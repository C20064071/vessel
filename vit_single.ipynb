{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#シード値の固定\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/root/work/data/2021\"\n",
    "result_path = \"/root/work/result/ViT/depth4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Resize((48,512))\n",
    "\n",
    "x_data=[]\n",
    "\n",
    "for i in range(1,302):\n",
    "    img=np.load(file=data_path+\"/deck_depth_map/data/hull\"+str(i)+\".npy\")\n",
    "    img=torch.tensor(img).reshape(1,48,521)\n",
    "    img=transform(img)\n",
    "\n",
    "    # img.numpy()\n",
    "    img=np.array(img[0])\n",
    "    x_data.append(img)\n",
    "\n",
    "x_data=np.array(x_data)\n",
    "x_data = np.delete(x_data, range(117, 119), axis=0)\n",
    "x_data=np.flip(x_data,axis=2)\n",
    "x_data=np.array(x_data).reshape(299,1,48,512)\n",
    "x_data=torch.tensor(x_data)\n",
    "\n",
    "X_MAX = x_data.max()\n",
    "x_data /= X_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =np.genfromtxt(data_path + \"/hist_naked.dat\", dtype=float, skip_header=1)\n",
    "y = np.delete(y, range(117, 119), axis=0)\n",
    "y_data=y[:,4:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HullDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2759061/1316001768.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data=torch.tensor(x_data).float().clone().detach()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "data=torch.tensor(x_data).float().clone().detach()\n",
    "targets=torch.tensor(y_data).float().clone().detach()\n",
    "\n",
    "dataset=HullDataset(data,targets)\n",
    "\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "\n",
    "train_loaders=[]\n",
    "val_loaders=[]\n",
    "\n",
    "for train_index,val_index in kfold.split(dataset):\n",
    "    train_dataset=Subset(dataset,train_index)\n",
    "    val_dataset=Subset(dataset,val_index)\n",
    "\n",
    "    train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer,num_epochs, train_loader, test_loader, device, history,fold):\n",
    "\n",
    "    # tqdmライブラリのインポート\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    base_epochs = len(history)\n",
    "  \n",
    "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
    "\n",
    "        # 1エポックあたりの累積損失(平均化前)\n",
    "        train_loss, val_loss = 0, 0\n",
    "\n",
    "        best_val_loss=1.0\n",
    "\n",
    "        # 1エポックあたりのデータ累積件数\n",
    "        n_train, n_test = 0, 0\n",
    "\n",
    "        #訓練フェーズ\n",
    "        net.train()\n",
    "        # for inputs, labels in tqdm(train_loader):\n",
    "        for inputs, labels in train_loader:\n",
    "            # 1バッチあたりのデータ件数\n",
    "            train_batch_size = len(labels)\n",
    "            # 1エポックあたりのデータ累積件数\n",
    "            n_train += train_batch_size\n",
    "    \n",
    "            # GPUヘ転送\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 予測計算\n",
    "            loss = net(inputs, labels)\n",
    "\n",
    "            # 勾配計算\n",
    "            loss.backward()\n",
    "\n",
    "            # パラメータ修正\n",
    "            optimizer.step()\n",
    "\n",
    "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
    "            train_loss += loss.item() * train_batch_size \n",
    "\n",
    "        #予測フェーズ\n",
    "        net.eval()\n",
    "\n",
    "        for inputs_test, labels_test in test_loader:\n",
    "            # 1バッチあたりのデータ件数\n",
    "            test_batch_size = len(labels_test)\n",
    "            # 1エポックあたりのデータ累積件数\n",
    "            n_test += test_batch_size\n",
    "\n",
    "            # GPUヘ転送\n",
    "            inputs_test = inputs_test.to(device)\n",
    "            labels_test = labels_test.to(device)\n",
    "\n",
    "            # 予測計算\n",
    "            loss_test = net(inputs_test, labels_test)\n",
    "\n",
    "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
    "            val_loss +=  loss_test.item() * test_batch_size\n",
    "\n",
    "        # 損失計算\n",
    "        rmse_train_loss=(train_loss / n_train)**0.5\n",
    "        rmse_val_loss=(val_loss / n_test)**0.5     \n",
    "    \n",
    "\n",
    "        # 結果表示\n",
    "        if (epoch+1)%10==0:\n",
    "             print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}],rmse_train_loss: {rmse_train_loss:.5f},rmse_val_loss: {rmse_val_loss:.5f}')\n",
    "        # 記録\n",
    "        item = np.array([epoch+1,\n",
    "                        rmse_train_loss,rmse_val_loss])\n",
    "\n",
    "        history = np.vstack((history, item))\n",
    "\n",
    "        save_path = result_path+'/model'+str(fold)+'.pth'\n",
    "\n",
    "        if rmse_val_loss<best_val_loss:\n",
    "            best_val_loss=rmse_val_loss\n",
    "            # モデルの状態辞書を取得\n",
    "            model_state = net.state_dict()\n",
    "            # モデルの状態辞書を保存\n",
    "            torch.save(model_state, save_path)\n",
    "        \n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vessel_models.vessel_ViT import vessel_ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/2000],rmse_train_loss: 0.10877,rmse_val_loss: 0.07523\n",
      "Epoch [20/2000],rmse_train_loss: 0.07476,rmse_val_loss: 0.04202\n",
      "Epoch [30/2000],rmse_train_loss: 0.06913,rmse_val_loss: 0.05641\n",
      "Epoch [40/2000],rmse_train_loss: 0.06825,rmse_val_loss: 0.05021\n",
      "Epoch [50/2000],rmse_train_loss: 0.06757,rmse_val_loss: 0.05016\n",
      "Epoch [60/2000],rmse_train_loss: 0.07402,rmse_val_loss: 0.04862\n",
      "Epoch [70/2000],rmse_train_loss: 0.06946,rmse_val_loss: 0.05113\n",
      "Epoch [80/2000],rmse_train_loss: 0.06743,rmse_val_loss: 0.04890\n",
      "Epoch [90/2000],rmse_train_loss: 0.07009,rmse_val_loss: 0.04732\n",
      "Epoch [100/2000],rmse_train_loss: 0.06994,rmse_val_loss: 0.05113\n",
      "Epoch [110/2000],rmse_train_loss: 0.06771,rmse_val_loss: 0.04788\n",
      "Epoch [120/2000],rmse_train_loss: 0.07033,rmse_val_loss: 0.04664\n",
      "Epoch [130/2000],rmse_train_loss: 0.07113,rmse_val_loss: 0.05719\n",
      "Epoch [140/2000],rmse_train_loss: 0.06818,rmse_val_loss: 0.06159\n",
      "Epoch [150/2000],rmse_train_loss: 0.06719,rmse_val_loss: 0.04622\n",
      "Epoch [160/2000],rmse_train_loss: 0.06531,rmse_val_loss: 0.04688\n",
      "Epoch [170/2000],rmse_train_loss: 0.06907,rmse_val_loss: 0.05430\n",
      "Epoch [180/2000],rmse_train_loss: 0.07322,rmse_val_loss: 0.04212\n",
      "Epoch [190/2000],rmse_train_loss: 0.06653,rmse_val_loss: 0.04786\n",
      "Epoch [200/2000],rmse_train_loss: 0.06780,rmse_val_loss: 0.04626\n",
      "Epoch [210/2000],rmse_train_loss: 0.06738,rmse_val_loss: 0.04147\n",
      "Epoch [220/2000],rmse_train_loss: 0.06401,rmse_val_loss: 0.06171\n",
      "Epoch [230/2000],rmse_train_loss: 0.06380,rmse_val_loss: 0.04411\n",
      "Epoch [240/2000],rmse_train_loss: 0.07370,rmse_val_loss: 0.08774\n",
      "Epoch [250/2000],rmse_train_loss: 0.07130,rmse_val_loss: 0.04231\n",
      "Epoch [260/2000],rmse_train_loss: 0.06361,rmse_val_loss: 0.04353\n",
      "Epoch [270/2000],rmse_train_loss: 0.07198,rmse_val_loss: 0.04760\n",
      "Epoch [280/2000],rmse_train_loss: 0.06567,rmse_val_loss: 0.04933\n",
      "Epoch [290/2000],rmse_train_loss: 0.06417,rmse_val_loss: 0.05570\n",
      "Epoch [300/2000],rmse_train_loss: 0.06626,rmse_val_loss: 0.05665\n",
      "Epoch [310/2000],rmse_train_loss: 0.06912,rmse_val_loss: 0.04396\n",
      "Epoch [320/2000],rmse_train_loss: 0.06873,rmse_val_loss: 0.04388\n",
      "Epoch [330/2000],rmse_train_loss: 0.05569,rmse_val_loss: 0.04219\n",
      "Epoch [340/2000],rmse_train_loss: 0.05712,rmse_val_loss: 0.04456\n",
      "Epoch [350/2000],rmse_train_loss: 0.05437,rmse_val_loss: 0.04439\n",
      "Epoch [360/2000],rmse_train_loss: 0.06841,rmse_val_loss: 0.04645\n",
      "Epoch [370/2000],rmse_train_loss: 0.05979,rmse_val_loss: 0.03582\n",
      "Epoch [380/2000],rmse_train_loss: 0.04870,rmse_val_loss: 0.04269\n",
      "Epoch [390/2000],rmse_train_loss: 0.04791,rmse_val_loss: 0.03777\n",
      "Epoch [400/2000],rmse_train_loss: 0.04994,rmse_val_loss: 0.03658\n",
      "Epoch [410/2000],rmse_train_loss: 0.04056,rmse_val_loss: 0.03955\n",
      "Epoch [420/2000],rmse_train_loss: 0.04226,rmse_val_loss: 0.03241\n",
      "Epoch [430/2000],rmse_train_loss: 0.03718,rmse_val_loss: 0.03613\n",
      "Epoch [440/2000],rmse_train_loss: 0.03773,rmse_val_loss: 0.03326\n",
      "Epoch [450/2000],rmse_train_loss: 0.03470,rmse_val_loss: 0.03274\n",
      "Epoch [460/2000],rmse_train_loss: 0.03226,rmse_val_loss: 0.03076\n",
      "Epoch [470/2000],rmse_train_loss: 0.02745,rmse_val_loss: 0.03015\n",
      "Epoch [480/2000],rmse_train_loss: 0.02667,rmse_val_loss: 0.03178\n",
      "Epoch [490/2000],rmse_train_loss: 0.02477,rmse_val_loss: 0.02680\n",
      "Epoch [500/2000],rmse_train_loss: 0.02411,rmse_val_loss: 0.02827\n",
      "Epoch [510/2000],rmse_train_loss: 0.02870,rmse_val_loss: 0.02732\n",
      "Epoch [520/2000],rmse_train_loss: 0.02173,rmse_val_loss: 0.02897\n",
      "Epoch [530/2000],rmse_train_loss: 0.01789,rmse_val_loss: 0.02582\n",
      "Epoch [540/2000],rmse_train_loss: 0.03868,rmse_val_loss: 0.04521\n",
      "Epoch [550/2000],rmse_train_loss: 0.02513,rmse_val_loss: 0.03219\n",
      "Epoch [560/2000],rmse_train_loss: 0.03718,rmse_val_loss: 0.03207\n",
      "Epoch [570/2000],rmse_train_loss: 0.03250,rmse_val_loss: 0.03315\n",
      "Epoch [580/2000],rmse_train_loss: 0.03383,rmse_val_loss: 0.03707\n",
      "Epoch [590/2000],rmse_train_loss: 0.03154,rmse_val_loss: 0.03267\n",
      "Epoch [600/2000],rmse_train_loss: 0.02377,rmse_val_loss: 0.03777\n",
      "Epoch [610/2000],rmse_train_loss: 0.02114,rmse_val_loss: 0.02457\n",
      "Epoch [620/2000],rmse_train_loss: 0.01689,rmse_val_loss: 0.02706\n",
      "Epoch [630/2000],rmse_train_loss: 0.01746,rmse_val_loss: 0.02310\n",
      "Epoch [640/2000],rmse_train_loss: 0.01890,rmse_val_loss: 0.02791\n",
      "Epoch [650/2000],rmse_train_loss: 0.02897,rmse_val_loss: 0.02656\n",
      "Epoch [660/2000],rmse_train_loss: 0.03195,rmse_val_loss: 0.02570\n",
      "Epoch [670/2000],rmse_train_loss: 0.01576,rmse_val_loss: 0.02353\n",
      "Epoch [680/2000],rmse_train_loss: 0.01235,rmse_val_loss: 0.02029\n",
      "Epoch [690/2000],rmse_train_loss: 0.01261,rmse_val_loss: 0.02417\n",
      "Epoch [700/2000],rmse_train_loss: 0.01355,rmse_val_loss: 0.02350\n",
      "Epoch [710/2000],rmse_train_loss: 0.01513,rmse_val_loss: 0.02814\n",
      "Epoch [720/2000],rmse_train_loss: 0.01175,rmse_val_loss: 0.02873\n",
      "Epoch [730/2000],rmse_train_loss: 0.01021,rmse_val_loss: 0.02507\n",
      "Epoch [740/2000],rmse_train_loss: 0.01000,rmse_val_loss: 0.02528\n",
      "Epoch [750/2000],rmse_train_loss: 0.00859,rmse_val_loss: 0.02383\n",
      "Epoch [760/2000],rmse_train_loss: 0.00805,rmse_val_loss: 0.03044\n",
      "Epoch [770/2000],rmse_train_loss: 0.01129,rmse_val_loss: 0.02834\n",
      "Epoch [780/2000],rmse_train_loss: 0.05835,rmse_val_loss: 0.04227\n",
      "Epoch [790/2000],rmse_train_loss: 0.02261,rmse_val_loss: 0.03541\n",
      "Epoch [800/2000],rmse_train_loss: 0.01690,rmse_val_loss: 0.02298\n",
      "Epoch [810/2000],rmse_train_loss: 0.01402,rmse_val_loss: 0.02243\n",
      "Epoch [820/2000],rmse_train_loss: 0.01017,rmse_val_loss: 0.02235\n",
      "Epoch [830/2000],rmse_train_loss: 0.01024,rmse_val_loss: 0.02624\n",
      "Epoch [840/2000],rmse_train_loss: 0.01808,rmse_val_loss: 0.02234\n",
      "Epoch [850/2000],rmse_train_loss: 0.00944,rmse_val_loss: 0.02419\n",
      "Epoch [860/2000],rmse_train_loss: 0.00568,rmse_val_loss: 0.02283\n",
      "Epoch [870/2000],rmse_train_loss: 0.00617,rmse_val_loss: 0.02325\n",
      "Epoch [880/2000],rmse_train_loss: 0.00559,rmse_val_loss: 0.02381\n",
      "Epoch [890/2000],rmse_train_loss: 0.00612,rmse_val_loss: 0.02613\n",
      "Epoch [900/2000],rmse_train_loss: 0.00536,rmse_val_loss: 0.02304\n",
      "Epoch [910/2000],rmse_train_loss: 0.00709,rmse_val_loss: 0.02083\n",
      "Epoch [920/2000],rmse_train_loss: 0.04739,rmse_val_loss: 0.02720\n",
      "Epoch [930/2000],rmse_train_loss: 0.02353,rmse_val_loss: 0.02909\n",
      "Epoch [940/2000],rmse_train_loss: 0.01327,rmse_val_loss: 0.02176\n",
      "Epoch [950/2000],rmse_train_loss: 0.01109,rmse_val_loss: 0.02271\n",
      "Epoch [960/2000],rmse_train_loss: 0.00722,rmse_val_loss: 0.02206\n",
      "Epoch [970/2000],rmse_train_loss: 0.00706,rmse_val_loss: 0.02233\n",
      "Epoch [980/2000],rmse_train_loss: 0.01142,rmse_val_loss: 0.01802\n",
      "Epoch [990/2000],rmse_train_loss: 0.00706,rmse_val_loss: 0.01877\n",
      "Epoch [1000/2000],rmse_train_loss: 0.00642,rmse_val_loss: 0.02052\n",
      "Epoch [1010/2000],rmse_train_loss: 0.00496,rmse_val_loss: 0.02091\n",
      "Epoch [1020/2000],rmse_train_loss: 0.00349,rmse_val_loss: 0.02041\n",
      "Epoch [1030/2000],rmse_train_loss: 0.00727,rmse_val_loss: 0.02127\n",
      "Epoch [1040/2000],rmse_train_loss: 0.04152,rmse_val_loss: 0.02984\n",
      "Epoch [1050/2000],rmse_train_loss: 0.02589,rmse_val_loss: 0.03192\n",
      "Epoch [1060/2000],rmse_train_loss: 0.01547,rmse_val_loss: 0.03239\n",
      "Epoch [1070/2000],rmse_train_loss: 0.01163,rmse_val_loss: 0.02603\n",
      "Epoch [1080/2000],rmse_train_loss: 0.00713,rmse_val_loss: 0.02821\n",
      "Epoch [1090/2000],rmse_train_loss: 0.00487,rmse_val_loss: 0.02705\n",
      "Epoch [1100/2000],rmse_train_loss: 0.00508,rmse_val_loss: 0.02826\n",
      "Epoch [1110/2000],rmse_train_loss: 0.00608,rmse_val_loss: 0.02759\n",
      "Epoch [1120/2000],rmse_train_loss: 0.00441,rmse_val_loss: 0.02652\n",
      "Epoch [1130/2000],rmse_train_loss: 0.00666,rmse_val_loss: 0.02710\n",
      "Epoch [1140/2000],rmse_train_loss: 0.00492,rmse_val_loss: 0.02739\n",
      "Epoch [1150/2000],rmse_train_loss: 0.00504,rmse_val_loss: 0.02643\n",
      "Epoch [1160/2000],rmse_train_loss: 0.00434,rmse_val_loss: 0.02463\n",
      "Epoch [1170/2000],rmse_train_loss: 0.01069,rmse_val_loss: 0.03038\n",
      "Epoch [1180/2000],rmse_train_loss: 0.03542,rmse_val_loss: 0.03335\n",
      "Epoch [1190/2000],rmse_train_loss: 0.01968,rmse_val_loss: 0.02642\n",
      "Epoch [1200/2000],rmse_train_loss: 0.00837,rmse_val_loss: 0.02986\n",
      "Epoch [1210/2000],rmse_train_loss: 0.00671,rmse_val_loss: 0.02992\n",
      "Epoch [1220/2000],rmse_train_loss: 0.00582,rmse_val_loss: 0.02962\n",
      "Epoch [1230/2000],rmse_train_loss: 0.00456,rmse_val_loss: 0.03014\n",
      "Epoch [1240/2000],rmse_train_loss: 0.00607,rmse_val_loss: 0.02996\n",
      "Epoch [1250/2000],rmse_train_loss: 0.01030,rmse_val_loss: 0.02795\n",
      "Epoch [1260/2000],rmse_train_loss: 0.00739,rmse_val_loss: 0.02693\n",
      "Epoch [1270/2000],rmse_train_loss: 0.02318,rmse_val_loss: 0.02989\n",
      "Epoch [1280/2000],rmse_train_loss: 0.01494,rmse_val_loss: 0.02319\n",
      "Epoch [1290/2000],rmse_train_loss: 0.01658,rmse_val_loss: 0.03215\n",
      "Epoch [1300/2000],rmse_train_loss: 0.01078,rmse_val_loss: 0.02514\n",
      "Epoch [1310/2000],rmse_train_loss: 0.00731,rmse_val_loss: 0.02254\n",
      "Epoch [1320/2000],rmse_train_loss: 0.00429,rmse_val_loss: 0.02434\n",
      "Epoch [1330/2000],rmse_train_loss: 0.01221,rmse_val_loss: 0.02963\n",
      "Epoch [1340/2000],rmse_train_loss: 0.00750,rmse_val_loss: 0.02339\n",
      "Epoch [1350/2000],rmse_train_loss: 0.00328,rmse_val_loss: 0.02522\n",
      "Epoch [1360/2000],rmse_train_loss: 0.00290,rmse_val_loss: 0.02486\n",
      "Epoch [1370/2000],rmse_train_loss: 0.00260,rmse_val_loss: 0.02568\n",
      "Epoch [1380/2000],rmse_train_loss: 0.00235,rmse_val_loss: 0.02416\n",
      "Epoch [1390/2000],rmse_train_loss: 0.00287,rmse_val_loss: 0.02460\n",
      "Epoch [1400/2000],rmse_train_loss: 0.00194,rmse_val_loss: 0.02496\n",
      "Epoch [1410/2000],rmse_train_loss: 0.00370,rmse_val_loss: 0.02393\n",
      "Epoch [1420/2000],rmse_train_loss: 0.00453,rmse_val_loss: 0.02630\n",
      "Epoch [1430/2000],rmse_train_loss: 0.04250,rmse_val_loss: 0.03738\n",
      "Epoch [1440/2000],rmse_train_loss: 0.02187,rmse_val_loss: 0.04304\n",
      "Epoch [1450/2000],rmse_train_loss: 0.01752,rmse_val_loss: 0.03438\n",
      "Epoch [1460/2000],rmse_train_loss: 0.01087,rmse_val_loss: 0.03078\n",
      "Epoch [1470/2000],rmse_train_loss: 0.00685,rmse_val_loss: 0.03101\n",
      "Epoch [1480/2000],rmse_train_loss: 0.00759,rmse_val_loss: 0.03228\n",
      "Epoch [1490/2000],rmse_train_loss: 0.00438,rmse_val_loss: 0.03066\n",
      "Epoch [1500/2000],rmse_train_loss: 0.00520,rmse_val_loss: 0.03240\n",
      "Epoch [1510/2000],rmse_train_loss: 0.00446,rmse_val_loss: 0.03075\n",
      "Epoch [1520/2000],rmse_train_loss: 0.00312,rmse_val_loss: 0.03019\n",
      "Epoch [1530/2000],rmse_train_loss: 0.00433,rmse_val_loss: 0.03250\n",
      "Epoch [1540/2000],rmse_train_loss: 0.03160,rmse_val_loss: 0.04563\n",
      "Epoch [1550/2000],rmse_train_loss: 0.03918,rmse_val_loss: 0.03608\n",
      "Epoch [1560/2000],rmse_train_loss: 0.03038,rmse_val_loss: 0.03343\n",
      "Epoch [1570/2000],rmse_train_loss: 0.02170,rmse_val_loss: 0.02469\n",
      "Epoch [1580/2000],rmse_train_loss: 0.01520,rmse_val_loss: 0.02175\n",
      "Epoch [1590/2000],rmse_train_loss: 0.01354,rmse_val_loss: 0.02326\n",
      "Epoch [1600/2000],rmse_train_loss: 0.01157,rmse_val_loss: 0.02475\n",
      "Epoch [1610/2000],rmse_train_loss: 0.00801,rmse_val_loss: 0.02120\n",
      "Epoch [1620/2000],rmse_train_loss: 0.00480,rmse_val_loss: 0.02267\n",
      "Epoch [1630/2000],rmse_train_loss: 0.00473,rmse_val_loss: 0.02327\n",
      "Epoch [1640/2000],rmse_train_loss: 0.00499,rmse_val_loss: 0.02278\n",
      "Epoch [1650/2000],rmse_train_loss: 0.00436,rmse_val_loss: 0.02431\n",
      "Epoch [1660/2000],rmse_train_loss: 0.00304,rmse_val_loss: 0.02410\n",
      "Epoch [1670/2000],rmse_train_loss: 0.00653,rmse_val_loss: 0.02445\n",
      "Epoch [1680/2000],rmse_train_loss: 0.01943,rmse_val_loss: 0.02481\n",
      "Epoch [1690/2000],rmse_train_loss: 0.01633,rmse_val_loss: 0.02271\n",
      "Epoch [1700/2000],rmse_train_loss: 0.00958,rmse_val_loss: 0.02343\n",
      "Epoch [1710/2000],rmse_train_loss: 0.00756,rmse_val_loss: 0.02485\n",
      "Epoch [1720/2000],rmse_train_loss: 0.00451,rmse_val_loss: 0.02133\n",
      "Epoch [1730/2000],rmse_train_loss: 0.00491,rmse_val_loss: 0.02029\n",
      "Epoch [1740/2000],rmse_train_loss: 0.00356,rmse_val_loss: 0.02104\n",
      "Epoch [1750/2000],rmse_train_loss: 0.00431,rmse_val_loss: 0.02061\n",
      "Epoch [1760/2000],rmse_train_loss: 0.00780,rmse_val_loss: 0.01769\n",
      "Epoch [1770/2000],rmse_train_loss: 0.01826,rmse_val_loss: 0.02328\n",
      "Epoch [1780/2000],rmse_train_loss: 0.01280,rmse_val_loss: 0.02765\n",
      "Epoch [1790/2000],rmse_train_loss: 0.00684,rmse_val_loss: 0.02263\n",
      "Epoch [1800/2000],rmse_train_loss: 0.00413,rmse_val_loss: 0.02279\n",
      "Epoch [1810/2000],rmse_train_loss: 0.00297,rmse_val_loss: 0.02231\n",
      "Epoch [1820/2000],rmse_train_loss: 0.00493,rmse_val_loss: 0.02323\n",
      "Epoch [1830/2000],rmse_train_loss: 0.00264,rmse_val_loss: 0.02285\n",
      "Epoch [1840/2000],rmse_train_loss: 0.00271,rmse_val_loss: 0.02379\n",
      "Epoch [1850/2000],rmse_train_loss: 0.00688,rmse_val_loss: 0.02424\n",
      "Epoch [1860/2000],rmse_train_loss: 0.01291,rmse_val_loss: 0.02964\n",
      "Epoch [1870/2000],rmse_train_loss: 0.02328,rmse_val_loss: 0.02818\n",
      "Epoch [1880/2000],rmse_train_loss: 0.01787,rmse_val_loss: 0.02385\n",
      "Epoch [1890/2000],rmse_train_loss: 0.00676,rmse_val_loss: 0.02296\n",
      "Epoch [1900/2000],rmse_train_loss: 0.00545,rmse_val_loss: 0.02363\n",
      "Epoch [1910/2000],rmse_train_loss: 0.00399,rmse_val_loss: 0.02297\n",
      "Epoch [1920/2000],rmse_train_loss: 0.00345,rmse_val_loss: 0.02257\n",
      "Epoch [1930/2000],rmse_train_loss: 0.00396,rmse_val_loss: 0.02343\n",
      "Epoch [1940/2000],rmse_train_loss: 0.00296,rmse_val_loss: 0.02438\n",
      "Epoch [1950/2000],rmse_train_loss: 0.00324,rmse_val_loss: 0.02564\n",
      "Epoch [1960/2000],rmse_train_loss: 0.00396,rmse_val_loss: 0.02399\n",
      "Epoch [1970/2000],rmse_train_loss: 0.00381,rmse_val_loss: 0.02379\n",
      "Epoch [1980/2000],rmse_train_loss: 0.00382,rmse_val_loss: 0.02504\n",
      "Epoch [1990/2000],rmse_train_loss: 0.00199,rmse_val_loss: 0.02360\n",
      "Epoch [2000/2000],rmse_train_loss: 0.00264,rmse_val_loss: 0.02385\n",
      "Epoch [10/2000],rmse_train_loss: 0.10357,rmse_val_loss: 0.11897\n",
      "Epoch [20/2000],rmse_train_loss: 0.09476,rmse_val_loss: 0.11923\n",
      "Epoch [30/2000],rmse_train_loss: 0.06865,rmse_val_loss: 0.08606\n",
      "Epoch [40/2000],rmse_train_loss: 0.06320,rmse_val_loss: 0.08772\n",
      "Epoch [50/2000],rmse_train_loss: 0.06262,rmse_val_loss: 0.09440\n",
      "Epoch [60/2000],rmse_train_loss: 0.06006,rmse_val_loss: 0.08370\n",
      "Epoch [70/2000],rmse_train_loss: 0.06306,rmse_val_loss: 0.09463\n",
      "Epoch [80/2000],rmse_train_loss: 0.05915,rmse_val_loss: 0.08542\n",
      "Epoch [90/2000],rmse_train_loss: 0.05762,rmse_val_loss: 0.08714\n",
      "Epoch [100/2000],rmse_train_loss: 0.05658,rmse_val_loss: 0.08058\n",
      "Epoch [110/2000],rmse_train_loss: 0.06407,rmse_val_loss: 0.08481\n",
      "Epoch [120/2000],rmse_train_loss: 0.06409,rmse_val_loss: 0.08355\n",
      "Epoch [130/2000],rmse_train_loss: 0.05867,rmse_val_loss: 0.08404\n",
      "Epoch [140/2000],rmse_train_loss: 0.06079,rmse_val_loss: 0.08465\n",
      "Epoch [150/2000],rmse_train_loss: 0.05609,rmse_val_loss: 0.08508\n",
      "Epoch [160/2000],rmse_train_loss: 0.05647,rmse_val_loss: 0.08453\n",
      "Epoch [170/2000],rmse_train_loss: 0.05046,rmse_val_loss: 0.09686\n",
      "Epoch [180/2000],rmse_train_loss: 0.05030,rmse_val_loss: 0.08447\n",
      "Epoch [190/2000],rmse_train_loss: 0.05485,rmse_val_loss: 0.08140\n",
      "Epoch [200/2000],rmse_train_loss: 0.05644,rmse_val_loss: 0.08708\n",
      "Epoch [210/2000],rmse_train_loss: 0.05012,rmse_val_loss: 0.08399\n",
      "Epoch [220/2000],rmse_train_loss: 0.05108,rmse_val_loss: 0.07523\n",
      "Epoch [230/2000],rmse_train_loss: 0.05291,rmse_val_loss: 0.07502\n",
      "Epoch [240/2000],rmse_train_loss: 0.04681,rmse_val_loss: 0.07616\n",
      "Epoch [250/2000],rmse_train_loss: 0.04655,rmse_val_loss: 0.06742\n",
      "Epoch [260/2000],rmse_train_loss: 0.04458,rmse_val_loss: 0.07017\n",
      "Epoch [270/2000],rmse_train_loss: 0.04462,rmse_val_loss: 0.07001\n",
      "Epoch [280/2000],rmse_train_loss: 0.02941,rmse_val_loss: 0.06179\n",
      "Epoch [290/2000],rmse_train_loss: 0.03087,rmse_val_loss: 0.05731\n",
      "Epoch [300/2000],rmse_train_loss: 0.02911,rmse_val_loss: 0.07240\n",
      "Epoch [310/2000],rmse_train_loss: 0.02822,rmse_val_loss: 0.06716\n",
      "Epoch [320/2000],rmse_train_loss: 0.02637,rmse_val_loss: 0.06427\n",
      "Epoch [330/2000],rmse_train_loss: 0.02014,rmse_val_loss: 0.06151\n",
      "Epoch [340/2000],rmse_train_loss: 0.02454,rmse_val_loss: 0.06383\n",
      "Epoch [350/2000],rmse_train_loss: 0.01664,rmse_val_loss: 0.06340\n",
      "Epoch [360/2000],rmse_train_loss: 0.01267,rmse_val_loss: 0.06107\n",
      "Epoch [370/2000],rmse_train_loss: 0.01470,rmse_val_loss: 0.06289\n",
      "Epoch [380/2000],rmse_train_loss: 0.01004,rmse_val_loss: 0.06253\n",
      "Epoch [390/2000],rmse_train_loss: 0.01362,rmse_val_loss: 0.06224\n",
      "Epoch [400/2000],rmse_train_loss: 0.01101,rmse_val_loss: 0.06139\n",
      "Epoch [410/2000],rmse_train_loss: 0.02062,rmse_val_loss: 0.06429\n",
      "Epoch [420/2000],rmse_train_loss: 0.03203,rmse_val_loss: 0.06260\n",
      "Epoch [430/2000],rmse_train_loss: 0.03617,rmse_val_loss: 0.06201\n",
      "Epoch [440/2000],rmse_train_loss: 0.02473,rmse_val_loss: 0.05844\n",
      "Epoch [450/2000],rmse_train_loss: 0.01540,rmse_val_loss: 0.06336\n",
      "Epoch [460/2000],rmse_train_loss: 0.01222,rmse_val_loss: 0.06043\n",
      "Epoch [470/2000],rmse_train_loss: 0.01148,rmse_val_loss: 0.05977\n",
      "Epoch [480/2000],rmse_train_loss: 0.00954,rmse_val_loss: 0.06024\n",
      "Epoch [490/2000],rmse_train_loss: 0.00967,rmse_val_loss: 0.06223\n",
      "Epoch [500/2000],rmse_train_loss: 0.01336,rmse_val_loss: 0.05932\n",
      "Epoch [510/2000],rmse_train_loss: 0.02006,rmse_val_loss: 0.06786\n",
      "Epoch [520/2000],rmse_train_loss: 0.02045,rmse_val_loss: 0.07034\n",
      "Epoch [530/2000],rmse_train_loss: 0.03196,rmse_val_loss: 0.06508\n",
      "Epoch [540/2000],rmse_train_loss: 0.01999,rmse_val_loss: 0.05873\n",
      "Epoch [550/2000],rmse_train_loss: 0.01023,rmse_val_loss: 0.05775\n",
      "Epoch [560/2000],rmse_train_loss: 0.01404,rmse_val_loss: 0.06321\n",
      "Epoch [570/2000],rmse_train_loss: 0.00832,rmse_val_loss: 0.05808\n",
      "Epoch [580/2000],rmse_train_loss: 0.00787,rmse_val_loss: 0.05799\n",
      "Epoch [590/2000],rmse_train_loss: 0.01209,rmse_val_loss: 0.06012\n",
      "Epoch [600/2000],rmse_train_loss: 0.00878,rmse_val_loss: 0.06184\n",
      "Epoch [610/2000],rmse_train_loss: 0.00705,rmse_val_loss: 0.06054\n",
      "Epoch [620/2000],rmse_train_loss: 0.01080,rmse_val_loss: 0.05726\n",
      "Epoch [630/2000],rmse_train_loss: 0.05311,rmse_val_loss: 0.08069\n",
      "Epoch [640/2000],rmse_train_loss: 0.02864,rmse_val_loss: 0.05551\n",
      "Epoch [650/2000],rmse_train_loss: 0.02947,rmse_val_loss: 0.07708\n",
      "Epoch [660/2000],rmse_train_loss: 0.01335,rmse_val_loss: 0.05352\n",
      "Epoch [670/2000],rmse_train_loss: 0.01848,rmse_val_loss: 0.06193\n",
      "Epoch [680/2000],rmse_train_loss: 0.01034,rmse_val_loss: 0.05818\n",
      "Epoch [690/2000],rmse_train_loss: 0.00764,rmse_val_loss: 0.05877\n",
      "Epoch [700/2000],rmse_train_loss: 0.00927,rmse_val_loss: 0.05716\n",
      "Epoch [710/2000],rmse_train_loss: 0.00561,rmse_val_loss: 0.05846\n",
      "Epoch [720/2000],rmse_train_loss: 0.00593,rmse_val_loss: 0.05623\n",
      "Epoch [730/2000],rmse_train_loss: 0.00767,rmse_val_loss: 0.05827\n",
      "Epoch [740/2000],rmse_train_loss: 0.00997,rmse_val_loss: 0.05977\n",
      "Epoch [750/2000],rmse_train_loss: 0.01264,rmse_val_loss: 0.06289\n",
      "Epoch [760/2000],rmse_train_loss: 0.03525,rmse_val_loss: 0.07216\n",
      "Epoch [770/2000],rmse_train_loss: 0.01655,rmse_val_loss: 0.06142\n",
      "Epoch [780/2000],rmse_train_loss: 0.00910,rmse_val_loss: 0.06112\n",
      "Epoch [790/2000],rmse_train_loss: 0.00843,rmse_val_loss: 0.05879\n",
      "Epoch [800/2000],rmse_train_loss: 0.00535,rmse_val_loss: 0.06167\n",
      "Epoch [810/2000],rmse_train_loss: 0.00643,rmse_val_loss: 0.05947\n",
      "Epoch [820/2000],rmse_train_loss: 0.00506,rmse_val_loss: 0.05867\n",
      "Epoch [830/2000],rmse_train_loss: 0.00394,rmse_val_loss: 0.05921\n",
      "Epoch [840/2000],rmse_train_loss: 0.00692,rmse_val_loss: 0.05907\n",
      "Epoch [850/2000],rmse_train_loss: 0.01888,rmse_val_loss: 0.06342\n",
      "Epoch [860/2000],rmse_train_loss: 0.03919,rmse_val_loss: 0.05999\n",
      "Epoch [870/2000],rmse_train_loss: 0.02773,rmse_val_loss: 0.06332\n",
      "Epoch [880/2000],rmse_train_loss: 0.03386,rmse_val_loss: 0.06641\n",
      "Epoch [890/2000],rmse_train_loss: 0.03191,rmse_val_loss: 0.06320\n",
      "Epoch [900/2000],rmse_train_loss: 0.01745,rmse_val_loss: 0.05740\n",
      "Epoch [910/2000],rmse_train_loss: 0.01485,rmse_val_loss: 0.05799\n",
      "Epoch [920/2000],rmse_train_loss: 0.01163,rmse_val_loss: 0.05592\n",
      "Epoch [930/2000],rmse_train_loss: 0.01240,rmse_val_loss: 0.05781\n",
      "Epoch [940/2000],rmse_train_loss: 0.00972,rmse_val_loss: 0.05605\n",
      "Epoch [950/2000],rmse_train_loss: 0.00994,rmse_val_loss: 0.05549\n",
      "Epoch [960/2000],rmse_train_loss: 0.01119,rmse_val_loss: 0.05523\n",
      "Epoch [970/2000],rmse_train_loss: 0.00916,rmse_val_loss: 0.05651\n",
      "Epoch [980/2000],rmse_train_loss: 0.01110,rmse_val_loss: 0.05676\n",
      "Epoch [990/2000],rmse_train_loss: 0.01264,rmse_val_loss: 0.05820\n",
      "Epoch [1000/2000],rmse_train_loss: 0.00827,rmse_val_loss: 0.06009\n",
      "Epoch [1010/2000],rmse_train_loss: 0.00739,rmse_val_loss: 0.05956\n",
      "Epoch [1020/2000],rmse_train_loss: 0.00820,rmse_val_loss: 0.05791\n",
      "Epoch [1030/2000],rmse_train_loss: 0.00581,rmse_val_loss: 0.05766\n",
      "Epoch [1040/2000],rmse_train_loss: 0.00884,rmse_val_loss: 0.05620\n",
      "Epoch [1050/2000],rmse_train_loss: 0.00758,rmse_val_loss: 0.05832\n",
      "Epoch [1060/2000],rmse_train_loss: 0.00453,rmse_val_loss: 0.05666\n",
      "Epoch [1070/2000],rmse_train_loss: 0.01222,rmse_val_loss: 0.05650\n",
      "Epoch [1080/2000],rmse_train_loss: 0.03073,rmse_val_loss: 0.05950\n",
      "Epoch [1090/2000],rmse_train_loss: 0.02600,rmse_val_loss: 0.05544\n",
      "Epoch [1100/2000],rmse_train_loss: 0.01571,rmse_val_loss: 0.05936\n",
      "Epoch [1110/2000],rmse_train_loss: 0.00905,rmse_val_loss: 0.05782\n",
      "Epoch [1120/2000],rmse_train_loss: 0.00874,rmse_val_loss: 0.05709\n",
      "Epoch [1130/2000],rmse_train_loss: 0.00589,rmse_val_loss: 0.05740\n",
      "Epoch [1140/2000],rmse_train_loss: 0.00607,rmse_val_loss: 0.05753\n",
      "Epoch [1150/2000],rmse_train_loss: 0.00803,rmse_val_loss: 0.05764\n",
      "Epoch [1160/2000],rmse_train_loss: 0.00922,rmse_val_loss: 0.05545\n",
      "Epoch [1170/2000],rmse_train_loss: 0.01089,rmse_val_loss: 0.06092\n",
      "Epoch [1180/2000],rmse_train_loss: 0.01760,rmse_val_loss: 0.06022\n",
      "Epoch [1190/2000],rmse_train_loss: 0.02515,rmse_val_loss: 0.05749\n",
      "Epoch [1200/2000],rmse_train_loss: 0.00898,rmse_val_loss: 0.05519\n",
      "Epoch [1210/2000],rmse_train_loss: 0.00604,rmse_val_loss: 0.05535\n",
      "Epoch [1220/2000],rmse_train_loss: 0.00382,rmse_val_loss: 0.05473\n",
      "Epoch [1230/2000],rmse_train_loss: 0.00418,rmse_val_loss: 0.05386\n",
      "Epoch [1240/2000],rmse_train_loss: 0.00339,rmse_val_loss: 0.05524\n",
      "Epoch [1250/2000],rmse_train_loss: 0.00394,rmse_val_loss: 0.05499\n",
      "Epoch [1260/2000],rmse_train_loss: 0.00298,rmse_val_loss: 0.05525\n",
      "Epoch [1270/2000],rmse_train_loss: 0.00501,rmse_val_loss: 0.05555\n",
      "Epoch [1280/2000],rmse_train_loss: 0.01104,rmse_val_loss: 0.05959\n",
      "Epoch [1290/2000],rmse_train_loss: 0.03248,rmse_val_loss: 0.06752\n",
      "Epoch [1300/2000],rmse_train_loss: 0.01130,rmse_val_loss: 0.05884\n",
      "Epoch [1310/2000],rmse_train_loss: 0.01002,rmse_val_loss: 0.05829\n",
      "Epoch [1320/2000],rmse_train_loss: 0.00646,rmse_val_loss: 0.06111\n",
      "Epoch [1330/2000],rmse_train_loss: 0.00409,rmse_val_loss: 0.06017\n",
      "Epoch [1340/2000],rmse_train_loss: 0.00476,rmse_val_loss: 0.06197\n",
      "Epoch [1350/2000],rmse_train_loss: 0.00295,rmse_val_loss: 0.05854\n",
      "Epoch [1360/2000],rmse_train_loss: 0.00539,rmse_val_loss: 0.05836\n",
      "Epoch [1370/2000],rmse_train_loss: 0.01116,rmse_val_loss: 0.06171\n",
      "Epoch [1380/2000],rmse_train_loss: 0.02170,rmse_val_loss: 0.07831\n",
      "Epoch [1390/2000],rmse_train_loss: 0.01961,rmse_val_loss: 0.05778\n",
      "Epoch [1400/2000],rmse_train_loss: 0.01259,rmse_val_loss: 0.05928\n",
      "Epoch [1410/2000],rmse_train_loss: 0.00838,rmse_val_loss: 0.05705\n",
      "Epoch [1420/2000],rmse_train_loss: 0.00485,rmse_val_loss: 0.05565\n",
      "Epoch [1430/2000],rmse_train_loss: 0.00707,rmse_val_loss: 0.05609\n",
      "Epoch [1440/2000],rmse_train_loss: 0.00459,rmse_val_loss: 0.05463\n",
      "Epoch [1450/2000],rmse_train_loss: 0.00326,rmse_val_loss: 0.05548\n",
      "Epoch [1460/2000],rmse_train_loss: 0.00287,rmse_val_loss: 0.05548\n",
      "Epoch [1470/2000],rmse_train_loss: 0.00385,rmse_val_loss: 0.05463\n",
      "Epoch [1480/2000],rmse_train_loss: 0.00340,rmse_val_loss: 0.05496\n",
      "Epoch [1490/2000],rmse_train_loss: 0.00358,rmse_val_loss: 0.05606\n",
      "Epoch [1500/2000],rmse_train_loss: 0.00698,rmse_val_loss: 0.05602\n",
      "Epoch [1510/2000],rmse_train_loss: 0.00790,rmse_val_loss: 0.05677\n",
      "Epoch [1520/2000],rmse_train_loss: 0.01943,rmse_val_loss: 0.05823\n",
      "Epoch [1530/2000],rmse_train_loss: 0.01310,rmse_val_loss: 0.05837\n",
      "Epoch [1540/2000],rmse_train_loss: 0.00616,rmse_val_loss: 0.05801\n",
      "Epoch [1550/2000],rmse_train_loss: 0.00432,rmse_val_loss: 0.05791\n",
      "Epoch [1560/2000],rmse_train_loss: 0.00286,rmse_val_loss: 0.05823\n",
      "Epoch [1570/2000],rmse_train_loss: 0.00301,rmse_val_loss: 0.05836\n",
      "Epoch [1580/2000],rmse_train_loss: 0.00601,rmse_val_loss: 0.05626\n",
      "Epoch [1590/2000],rmse_train_loss: 0.00371,rmse_val_loss: 0.05829\n",
      "Epoch [1600/2000],rmse_train_loss: 0.00206,rmse_val_loss: 0.05739\n",
      "Epoch [1610/2000],rmse_train_loss: 0.00254,rmse_val_loss: 0.05706\n",
      "Epoch [1620/2000],rmse_train_loss: 0.00636,rmse_val_loss: 0.05704\n",
      "Epoch [1630/2000],rmse_train_loss: 0.02167,rmse_val_loss: 0.06393\n",
      "Epoch [1640/2000],rmse_train_loss: 0.03501,rmse_val_loss: 0.05759\n",
      "Epoch [1650/2000],rmse_train_loss: 0.01276,rmse_val_loss: 0.06135\n",
      "Epoch [1660/2000],rmse_train_loss: 0.00752,rmse_val_loss: 0.05616\n",
      "Epoch [1670/2000],rmse_train_loss: 0.00438,rmse_val_loss: 0.05608\n",
      "Epoch [1680/2000],rmse_train_loss: 0.00280,rmse_val_loss: 0.05571\n",
      "Epoch [1690/2000],rmse_train_loss: 0.00281,rmse_val_loss: 0.05499\n",
      "Epoch [1700/2000],rmse_train_loss: 0.00302,rmse_val_loss: 0.05576\n",
      "Epoch [1710/2000],rmse_train_loss: 0.00308,rmse_val_loss: 0.05561\n",
      "Epoch [1720/2000],rmse_train_loss: 0.00476,rmse_val_loss: 0.05545\n",
      "Epoch [1730/2000],rmse_train_loss: 0.00277,rmse_val_loss: 0.05456\n",
      "Epoch [1740/2000],rmse_train_loss: 0.00401,rmse_val_loss: 0.05424\n",
      "Epoch [1750/2000],rmse_train_loss: 0.00353,rmse_val_loss: 0.05514\n",
      "Epoch [1760/2000],rmse_train_loss: 0.00318,rmse_val_loss: 0.05557\n",
      "Epoch [1770/2000],rmse_train_loss: 0.00967,rmse_val_loss: 0.05563\n",
      "Epoch [1780/2000],rmse_train_loss: 0.03280,rmse_val_loss: 0.06154\n",
      "Epoch [1790/2000],rmse_train_loss: 0.01443,rmse_val_loss: 0.05397\n",
      "Epoch [1800/2000],rmse_train_loss: 0.00805,rmse_val_loss: 0.05835\n",
      "Epoch [1810/2000],rmse_train_loss: 0.00520,rmse_val_loss: 0.05804\n",
      "Epoch [1820/2000],rmse_train_loss: 0.00326,rmse_val_loss: 0.05823\n",
      "Epoch [1830/2000],rmse_train_loss: 0.00352,rmse_val_loss: 0.05761\n",
      "Epoch [1840/2000],rmse_train_loss: 0.00224,rmse_val_loss: 0.05744\n",
      "Epoch [1850/2000],rmse_train_loss: 0.00200,rmse_val_loss: 0.05819\n",
      "Epoch [1860/2000],rmse_train_loss: 0.00248,rmse_val_loss: 0.05809\n",
      "Epoch [1870/2000],rmse_train_loss: 0.00271,rmse_val_loss: 0.05700\n",
      "Epoch [1880/2000],rmse_train_loss: 0.00199,rmse_val_loss: 0.05792\n",
      "Epoch [1890/2000],rmse_train_loss: 0.00435,rmse_val_loss: 0.05873\n",
      "Epoch [1900/2000],rmse_train_loss: 0.01010,rmse_val_loss: 0.05582\n",
      "Epoch [1910/2000],rmse_train_loss: 0.03877,rmse_val_loss: 0.06175\n",
      "Epoch [1920/2000],rmse_train_loss: 0.01561,rmse_val_loss: 0.05435\n",
      "Epoch [1930/2000],rmse_train_loss: 0.01409,rmse_val_loss: 0.05490\n",
      "Epoch [1940/2000],rmse_train_loss: 0.00929,rmse_val_loss: 0.05163\n",
      "Epoch [1950/2000],rmse_train_loss: 0.00719,rmse_val_loss: 0.05224\n",
      "Epoch [1960/2000],rmse_train_loss: 0.00945,rmse_val_loss: 0.05090\n",
      "Epoch [1970/2000],rmse_train_loss: 0.00663,rmse_val_loss: 0.05108\n",
      "Epoch [1980/2000],rmse_train_loss: 0.00487,rmse_val_loss: 0.05002\n",
      "Epoch [1990/2000],rmse_train_loss: 0.00412,rmse_val_loss: 0.04968\n",
      "Epoch [2000/2000],rmse_train_loss: 0.00363,rmse_val_loss: 0.05105\n",
      "Epoch [10/2000],rmse_train_loss: 0.10314,rmse_val_loss: 0.08680\n",
      "Epoch [20/2000],rmse_train_loss: 0.10334,rmse_val_loss: 0.08419\n",
      "Epoch [30/2000],rmse_train_loss: 0.07606,rmse_val_loss: 0.06354\n",
      "Epoch [40/2000],rmse_train_loss: 0.08246,rmse_val_loss: 0.09752\n",
      "Epoch [50/2000],rmse_train_loss: 0.06958,rmse_val_loss: 0.05719\n",
      "Epoch [60/2000],rmse_train_loss: 0.06737,rmse_val_loss: 0.05691\n",
      "Epoch [70/2000],rmse_train_loss: 0.06778,rmse_val_loss: 0.05173\n",
      "Epoch [80/2000],rmse_train_loss: 0.06554,rmse_val_loss: 0.05787\n",
      "Epoch [90/2000],rmse_train_loss: 0.07173,rmse_val_loss: 0.06228\n",
      "Epoch [100/2000],rmse_train_loss: 0.07286,rmse_val_loss: 0.06422\n",
      "Epoch [110/2000],rmse_train_loss: 0.06191,rmse_val_loss: 0.05514\n",
      "Epoch [120/2000],rmse_train_loss: 0.06598,rmse_val_loss: 0.05661\n",
      "Epoch [130/2000],rmse_train_loss: 0.06140,rmse_val_loss: 0.05439\n",
      "Epoch [140/2000],rmse_train_loss: 0.06329,rmse_val_loss: 0.06126\n",
      "Epoch [150/2000],rmse_train_loss: 0.05676,rmse_val_loss: 0.04313\n",
      "Epoch [160/2000],rmse_train_loss: 0.04973,rmse_val_loss: 0.04227\n",
      "Epoch [170/2000],rmse_train_loss: 0.04320,rmse_val_loss: 0.04387\n",
      "Epoch [180/2000],rmse_train_loss: 0.04780,rmse_val_loss: 0.05381\n",
      "Epoch [190/2000],rmse_train_loss: 0.04381,rmse_val_loss: 0.03884\n",
      "Epoch [200/2000],rmse_train_loss: 0.03637,rmse_val_loss: 0.04208\n",
      "Epoch [210/2000],rmse_train_loss: 0.03553,rmse_val_loss: 0.03453\n",
      "Epoch [220/2000],rmse_train_loss: 0.02795,rmse_val_loss: 0.04015\n",
      "Epoch [230/2000],rmse_train_loss: 0.04476,rmse_val_loss: 0.04781\n",
      "Epoch [240/2000],rmse_train_loss: 0.02620,rmse_val_loss: 0.03886\n",
      "Epoch [250/2000],rmse_train_loss: 0.02401,rmse_val_loss: 0.04394\n",
      "Epoch [260/2000],rmse_train_loss: 0.02574,rmse_val_loss: 0.03722\n",
      "Epoch [270/2000],rmse_train_loss: 0.03304,rmse_val_loss: 0.04254\n",
      "Epoch [280/2000],rmse_train_loss: 0.02979,rmse_val_loss: 0.04325\n",
      "Epoch [290/2000],rmse_train_loss: 0.02275,rmse_val_loss: 0.04303\n",
      "Epoch [300/2000],rmse_train_loss: 0.02653,rmse_val_loss: 0.05134\n",
      "Epoch [310/2000],rmse_train_loss: 0.02088,rmse_val_loss: 0.04270\n",
      "Epoch [320/2000],rmse_train_loss: 0.02388,rmse_val_loss: 0.04574\n",
      "Epoch [330/2000],rmse_train_loss: 0.01948,rmse_val_loss: 0.04260\n",
      "Epoch [340/2000],rmse_train_loss: 0.04535,rmse_val_loss: 0.03310\n",
      "Epoch [350/2000],rmse_train_loss: 0.03062,rmse_val_loss: 0.04301\n",
      "Epoch [360/2000],rmse_train_loss: 0.03271,rmse_val_loss: 0.03604\n",
      "Epoch [370/2000],rmse_train_loss: 0.03414,rmse_val_loss: 0.04111\n",
      "Epoch [380/2000],rmse_train_loss: 0.02822,rmse_val_loss: 0.04598\n",
      "Epoch [390/2000],rmse_train_loss: 0.02145,rmse_val_loss: 0.04217\n",
      "Epoch [400/2000],rmse_train_loss: 0.02232,rmse_val_loss: 0.03346\n",
      "Epoch [410/2000],rmse_train_loss: 0.02436,rmse_val_loss: 0.03372\n",
      "Epoch [420/2000],rmse_train_loss: 0.01995,rmse_val_loss: 0.03259\n",
      "Epoch [430/2000],rmse_train_loss: 0.01589,rmse_val_loss: 0.03179\n",
      "Epoch [440/2000],rmse_train_loss: 0.01820,rmse_val_loss: 0.03184\n",
      "Epoch [450/2000],rmse_train_loss: 0.02878,rmse_val_loss: 0.03704\n",
      "Epoch [460/2000],rmse_train_loss: 0.02149,rmse_val_loss: 0.03941\n",
      "Epoch [470/2000],rmse_train_loss: 0.02802,rmse_val_loss: 0.04183\n",
      "Epoch [480/2000],rmse_train_loss: 0.01739,rmse_val_loss: 0.03548\n",
      "Epoch [490/2000],rmse_train_loss: 0.02336,rmse_val_loss: 0.03643\n",
      "Epoch [500/2000],rmse_train_loss: 0.02464,rmse_val_loss: 0.04779\n",
      "Epoch [510/2000],rmse_train_loss: 0.02030,rmse_val_loss: 0.03513\n",
      "Epoch [520/2000],rmse_train_loss: 0.02898,rmse_val_loss: 0.04141\n",
      "Epoch [530/2000],rmse_train_loss: 0.01522,rmse_val_loss: 0.03834\n",
      "Epoch [540/2000],rmse_train_loss: 0.01651,rmse_val_loss: 0.03636\n",
      "Epoch [550/2000],rmse_train_loss: 0.01374,rmse_val_loss: 0.03458\n",
      "Epoch [560/2000],rmse_train_loss: 0.01356,rmse_val_loss: 0.03435\n",
      "Epoch [570/2000],rmse_train_loss: 0.01646,rmse_val_loss: 0.03191\n",
      "Epoch [580/2000],rmse_train_loss: 0.06188,rmse_val_loss: 0.06329\n",
      "Epoch [590/2000],rmse_train_loss: 0.03469,rmse_val_loss: 0.04204\n",
      "Epoch [600/2000],rmse_train_loss: 0.02348,rmse_val_loss: 0.03304\n",
      "Epoch [610/2000],rmse_train_loss: 0.01964,rmse_val_loss: 0.03326\n",
      "Epoch [620/2000],rmse_train_loss: 0.02739,rmse_val_loss: 0.03366\n",
      "Epoch [630/2000],rmse_train_loss: 0.02496,rmse_val_loss: 0.04715\n",
      "Epoch [640/2000],rmse_train_loss: 0.01690,rmse_val_loss: 0.03286\n",
      "Epoch [650/2000],rmse_train_loss: 0.02944,rmse_val_loss: 0.04062\n",
      "Epoch [660/2000],rmse_train_loss: 0.01718,rmse_val_loss: 0.03244\n",
      "Epoch [670/2000],rmse_train_loss: 0.01386,rmse_val_loss: 0.03115\n",
      "Epoch [680/2000],rmse_train_loss: 0.01200,rmse_val_loss: 0.02847\n",
      "Epoch [690/2000],rmse_train_loss: 0.02144,rmse_val_loss: 0.05807\n",
      "Epoch [700/2000],rmse_train_loss: 0.02102,rmse_val_loss: 0.04451\n",
      "Epoch [710/2000],rmse_train_loss: 0.02224,rmse_val_loss: 0.03654\n",
      "Epoch [720/2000],rmse_train_loss: 0.01585,rmse_val_loss: 0.03205\n",
      "Epoch [730/2000],rmse_train_loss: 0.01350,rmse_val_loss: 0.03271\n",
      "Epoch [740/2000],rmse_train_loss: 0.02173,rmse_val_loss: 0.04581\n",
      "Epoch [750/2000],rmse_train_loss: 0.01419,rmse_val_loss: 0.03327\n",
      "Epoch [760/2000],rmse_train_loss: 0.01397,rmse_val_loss: 0.03036\n",
      "Epoch [770/2000],rmse_train_loss: 0.01100,rmse_val_loss: 0.03399\n",
      "Epoch [780/2000],rmse_train_loss: 0.03184,rmse_val_loss: 0.03607\n",
      "Epoch [790/2000],rmse_train_loss: 0.04451,rmse_val_loss: 0.04398\n",
      "Epoch [800/2000],rmse_train_loss: 0.02347,rmse_val_loss: 0.03443\n",
      "Epoch [810/2000],rmse_train_loss: 0.01438,rmse_val_loss: 0.02990\n",
      "Epoch [820/2000],rmse_train_loss: 0.01524,rmse_val_loss: 0.03096\n",
      "Epoch [830/2000],rmse_train_loss: 0.02949,rmse_val_loss: 0.04827\n",
      "Epoch [840/2000],rmse_train_loss: 0.01426,rmse_val_loss: 0.02790\n",
      "Epoch [850/2000],rmse_train_loss: 0.01566,rmse_val_loss: 0.02953\n",
      "Epoch [860/2000],rmse_train_loss: 0.01297,rmse_val_loss: 0.02958\n",
      "Epoch [870/2000],rmse_train_loss: 0.01108,rmse_val_loss: 0.02999\n",
      "Epoch [880/2000],rmse_train_loss: 0.01223,rmse_val_loss: 0.02768\n",
      "Epoch [890/2000],rmse_train_loss: 0.01091,rmse_val_loss: 0.02711\n",
      "Epoch [900/2000],rmse_train_loss: 0.01082,rmse_val_loss: 0.02533\n",
      "Epoch [910/2000],rmse_train_loss: 0.01594,rmse_val_loss: 0.02891\n",
      "Epoch [920/2000],rmse_train_loss: 0.01967,rmse_val_loss: 0.03000\n",
      "Epoch [930/2000],rmse_train_loss: 0.01711,rmse_val_loss: 0.03004\n",
      "Epoch [940/2000],rmse_train_loss: 0.01880,rmse_val_loss: 0.02784\n",
      "Epoch [950/2000],rmse_train_loss: 0.00979,rmse_val_loss: 0.02752\n",
      "Epoch [960/2000],rmse_train_loss: 0.01069,rmse_val_loss: 0.02530\n",
      "Epoch [970/2000],rmse_train_loss: 0.01100,rmse_val_loss: 0.02414\n",
      "Epoch [980/2000],rmse_train_loss: 0.02482,rmse_val_loss: 0.02864\n",
      "Epoch [990/2000],rmse_train_loss: 0.02219,rmse_val_loss: 0.02883\n",
      "Epoch [1000/2000],rmse_train_loss: 0.01027,rmse_val_loss: 0.02746\n",
      "Epoch [1010/2000],rmse_train_loss: 0.02534,rmse_val_loss: 0.04489\n",
      "Epoch [1020/2000],rmse_train_loss: 0.01998,rmse_val_loss: 0.02861\n",
      "Epoch [1030/2000],rmse_train_loss: 0.01286,rmse_val_loss: 0.02787\n",
      "Epoch [1040/2000],rmse_train_loss: 0.00939,rmse_val_loss: 0.02396\n",
      "Epoch [1050/2000],rmse_train_loss: 0.01080,rmse_val_loss: 0.02736\n",
      "Epoch [1060/2000],rmse_train_loss: 0.00813,rmse_val_loss: 0.02501\n",
      "Epoch [1070/2000],rmse_train_loss: 0.00783,rmse_val_loss: 0.02553\n",
      "Epoch [1080/2000],rmse_train_loss: 0.01482,rmse_val_loss: 0.03273\n",
      "Epoch [1090/2000],rmse_train_loss: 0.01523,rmse_val_loss: 0.03148\n",
      "Epoch [1100/2000],rmse_train_loss: 0.00974,rmse_val_loss: 0.02543\n",
      "Epoch [1110/2000],rmse_train_loss: 0.00869,rmse_val_loss: 0.02530\n",
      "Epoch [1120/2000],rmse_train_loss: 0.00656,rmse_val_loss: 0.02560\n",
      "Epoch [1130/2000],rmse_train_loss: 0.00698,rmse_val_loss: 0.02528\n",
      "Epoch [1140/2000],rmse_train_loss: 0.00728,rmse_val_loss: 0.02685\n",
      "Epoch [1150/2000],rmse_train_loss: 0.00709,rmse_val_loss: 0.02690\n",
      "Epoch [1160/2000],rmse_train_loss: 0.00615,rmse_val_loss: 0.02404\n",
      "Epoch [1170/2000],rmse_train_loss: 0.04039,rmse_val_loss: 0.07087\n",
      "Epoch [1180/2000],rmse_train_loss: 0.05175,rmse_val_loss: 0.03656\n",
      "Epoch [1190/2000],rmse_train_loss: 0.03828,rmse_val_loss: 0.05118\n",
      "Epoch [1200/2000],rmse_train_loss: 0.03109,rmse_val_loss: 0.04777\n",
      "Epoch [1210/2000],rmse_train_loss: 0.06258,rmse_val_loss: 0.04253\n",
      "Epoch [1220/2000],rmse_train_loss: 0.04121,rmse_val_loss: 0.04178\n",
      "Epoch [1230/2000],rmse_train_loss: 0.02490,rmse_val_loss: 0.03596\n",
      "Epoch [1240/2000],rmse_train_loss: 0.02339,rmse_val_loss: 0.03228\n",
      "Epoch [1250/2000],rmse_train_loss: 0.03211,rmse_val_loss: 0.03809\n",
      "Epoch [1260/2000],rmse_train_loss: 0.02208,rmse_val_loss: 0.03285\n",
      "Epoch [1270/2000],rmse_train_loss: 0.01981,rmse_val_loss: 0.03402\n",
      "Epoch [1280/2000],rmse_train_loss: 0.01982,rmse_val_loss: 0.03231\n",
      "Epoch [1290/2000],rmse_train_loss: 0.01659,rmse_val_loss: 0.02678\n",
      "Epoch [1300/2000],rmse_train_loss: 0.02867,rmse_val_loss: 0.03553\n",
      "Epoch [1310/2000],rmse_train_loss: 0.03347,rmse_val_loss: 0.03374\n",
      "Epoch [1320/2000],rmse_train_loss: 0.02322,rmse_val_loss: 0.03229\n",
      "Epoch [1330/2000],rmse_train_loss: 0.01630,rmse_val_loss: 0.02606\n",
      "Epoch [1340/2000],rmse_train_loss: 0.01717,rmse_val_loss: 0.02411\n",
      "Epoch [1350/2000],rmse_train_loss: 0.01440,rmse_val_loss: 0.02976\n",
      "Epoch [1360/2000],rmse_train_loss: 0.01143,rmse_val_loss: 0.02391\n",
      "Epoch [1370/2000],rmse_train_loss: 0.02611,rmse_val_loss: 0.02598\n",
      "Epoch [1380/2000],rmse_train_loss: 0.01717,rmse_val_loss: 0.02412\n",
      "Epoch [1390/2000],rmse_train_loss: 0.01258,rmse_val_loss: 0.02884\n",
      "Epoch [1400/2000],rmse_train_loss: 0.00974,rmse_val_loss: 0.02131\n",
      "Epoch [1410/2000],rmse_train_loss: 0.01498,rmse_val_loss: 0.02606\n",
      "Epoch [1420/2000],rmse_train_loss: 0.02306,rmse_val_loss: 0.03328\n",
      "Epoch [1430/2000],rmse_train_loss: 0.01080,rmse_val_loss: 0.02339\n",
      "Epoch [1440/2000],rmse_train_loss: 0.01129,rmse_val_loss: 0.02262\n",
      "Epoch [1450/2000],rmse_train_loss: 0.00842,rmse_val_loss: 0.02096\n",
      "Epoch [1460/2000],rmse_train_loss: 0.01703,rmse_val_loss: 0.02475\n",
      "Epoch [1470/2000],rmse_train_loss: 0.00907,rmse_val_loss: 0.02015\n",
      "Epoch [1480/2000],rmse_train_loss: 0.00910,rmse_val_loss: 0.02139\n",
      "Epoch [1490/2000],rmse_train_loss: 0.00626,rmse_val_loss: 0.01880\n",
      "Epoch [1500/2000],rmse_train_loss: 0.00472,rmse_val_loss: 0.01875\n",
      "Epoch [1510/2000],rmse_train_loss: 0.00425,rmse_val_loss: 0.01833\n",
      "Epoch [1520/2000],rmse_train_loss: 0.00389,rmse_val_loss: 0.01863\n",
      "Epoch [1530/2000],rmse_train_loss: 0.00508,rmse_val_loss: 0.01931\n",
      "Epoch [1540/2000],rmse_train_loss: 0.04399,rmse_val_loss: 0.03486\n",
      "Epoch [1550/2000],rmse_train_loss: 0.02010,rmse_val_loss: 0.02682\n",
      "Epoch [1560/2000],rmse_train_loss: 0.01573,rmse_val_loss: 0.02554\n",
      "Epoch [1570/2000],rmse_train_loss: 0.01290,rmse_val_loss: 0.02575\n",
      "Epoch [1580/2000],rmse_train_loss: 0.00947,rmse_val_loss: 0.01930\n",
      "Epoch [1590/2000],rmse_train_loss: 0.00781,rmse_val_loss: 0.02093\n",
      "Epoch [1600/2000],rmse_train_loss: 0.00818,rmse_val_loss: 0.02244\n",
      "Epoch [1610/2000],rmse_train_loss: 0.01014,rmse_val_loss: 0.02097\n",
      "Epoch [1620/2000],rmse_train_loss: 0.00598,rmse_val_loss: 0.02060\n",
      "Epoch [1630/2000],rmse_train_loss: 0.00612,rmse_val_loss: 0.02242\n",
      "Epoch [1640/2000],rmse_train_loss: 0.00823,rmse_val_loss: 0.01911\n",
      "Epoch [1650/2000],rmse_train_loss: 0.00521,rmse_val_loss: 0.02027\n",
      "Epoch [1660/2000],rmse_train_loss: 0.00447,rmse_val_loss: 0.01984\n",
      "Epoch [1670/2000],rmse_train_loss: 0.02862,rmse_val_loss: 0.03536\n",
      "Epoch [1680/2000],rmse_train_loss: 0.04494,rmse_val_loss: 0.04830\n",
      "Epoch [1690/2000],rmse_train_loss: 0.01890,rmse_val_loss: 0.02609\n",
      "Epoch [1700/2000],rmse_train_loss: 0.01569,rmse_val_loss: 0.03432\n",
      "Epoch [1710/2000],rmse_train_loss: 0.01572,rmse_val_loss: 0.03059\n",
      "Epoch [1720/2000],rmse_train_loss: 0.01521,rmse_val_loss: 0.03076\n",
      "Epoch [1730/2000],rmse_train_loss: 0.00910,rmse_val_loss: 0.02596\n",
      "Epoch [1740/2000],rmse_train_loss: 0.01099,rmse_val_loss: 0.02725\n",
      "Epoch [1750/2000],rmse_train_loss: 0.00705,rmse_val_loss: 0.02477\n",
      "Epoch [1760/2000],rmse_train_loss: 0.01252,rmse_val_loss: 0.03211\n",
      "Epoch [1770/2000],rmse_train_loss: 0.00982,rmse_val_loss: 0.02786\n",
      "Epoch [1780/2000],rmse_train_loss: 0.00746,rmse_val_loss: 0.02684\n",
      "Epoch [1790/2000],rmse_train_loss: 0.00708,rmse_val_loss: 0.02896\n",
      "Epoch [1800/2000],rmse_train_loss: 0.00913,rmse_val_loss: 0.02657\n",
      "Epoch [1810/2000],rmse_train_loss: 0.00618,rmse_val_loss: 0.02892\n",
      "Epoch [1820/2000],rmse_train_loss: 0.00716,rmse_val_loss: 0.02971\n",
      "Epoch [1830/2000],rmse_train_loss: 0.01104,rmse_val_loss: 0.02658\n",
      "Epoch [1840/2000],rmse_train_loss: 0.00587,rmse_val_loss: 0.02826\n",
      "Epoch [1850/2000],rmse_train_loss: 0.03148,rmse_val_loss: 0.02546\n",
      "Epoch [1860/2000],rmse_train_loss: 0.01481,rmse_val_loss: 0.02340\n",
      "Epoch [1870/2000],rmse_train_loss: 0.01119,rmse_val_loss: 0.02224\n",
      "Epoch [1880/2000],rmse_train_loss: 0.00841,rmse_val_loss: 0.02294\n",
      "Epoch [1890/2000],rmse_train_loss: 0.00762,rmse_val_loss: 0.02328\n",
      "Epoch [1900/2000],rmse_train_loss: 0.00809,rmse_val_loss: 0.01979\n",
      "Epoch [1910/2000],rmse_train_loss: 0.00901,rmse_val_loss: 0.02215\n",
      "Epoch [1920/2000],rmse_train_loss: 0.01088,rmse_val_loss: 0.02429\n",
      "Epoch [1930/2000],rmse_train_loss: 0.00803,rmse_val_loss: 0.02242\n",
      "Epoch [1940/2000],rmse_train_loss: 0.00561,rmse_val_loss: 0.02129\n",
      "Epoch [1950/2000],rmse_train_loss: 0.00516,rmse_val_loss: 0.02132\n",
      "Epoch [1960/2000],rmse_train_loss: 0.00431,rmse_val_loss: 0.02110\n",
      "Epoch [1970/2000],rmse_train_loss: 0.00999,rmse_val_loss: 0.02417\n",
      "Epoch [1980/2000],rmse_train_loss: 0.03285,rmse_val_loss: 0.03362\n",
      "Epoch [1990/2000],rmse_train_loss: 0.01069,rmse_val_loss: 0.02400\n",
      "Epoch [2000/2000],rmse_train_loss: 0.01020,rmse_val_loss: 0.02369\n",
      "Epoch [10/2000],rmse_train_loss: 0.09737,rmse_val_loss: 0.11102\n",
      "Epoch [20/2000],rmse_train_loss: 0.07201,rmse_val_loss: 0.08222\n",
      "Epoch [30/2000],rmse_train_loss: 0.06293,rmse_val_loss: 0.07452\n",
      "Epoch [40/2000],rmse_train_loss: 0.06609,rmse_val_loss: 0.07637\n",
      "Epoch [50/2000],rmse_train_loss: 0.06835,rmse_val_loss: 0.07563\n",
      "Epoch [60/2000],rmse_train_loss: 0.06523,rmse_val_loss: 0.07517\n",
      "Epoch [70/2000],rmse_train_loss: 0.06782,rmse_val_loss: 0.07586\n",
      "Epoch [80/2000],rmse_train_loss: 0.06470,rmse_val_loss: 0.07385\n",
      "Epoch [90/2000],rmse_train_loss: 0.06452,rmse_val_loss: 0.07256\n",
      "Epoch [100/2000],rmse_train_loss: 0.06588,rmse_val_loss: 0.07541\n",
      "Epoch [110/2000],rmse_train_loss: 0.06418,rmse_val_loss: 0.07385\n",
      "Epoch [120/2000],rmse_train_loss: 0.06567,rmse_val_loss: 0.07358\n",
      "Epoch [130/2000],rmse_train_loss: 0.06207,rmse_val_loss: 0.08565\n",
      "Epoch [140/2000],rmse_train_loss: 0.06196,rmse_val_loss: 0.07601\n",
      "Epoch [150/2000],rmse_train_loss: 0.06073,rmse_val_loss: 0.08126\n",
      "Epoch [160/2000],rmse_train_loss: 0.06596,rmse_val_loss: 0.07139\n",
      "Epoch [170/2000],rmse_train_loss: 0.06316,rmse_val_loss: 0.07326\n",
      "Epoch [180/2000],rmse_train_loss: 0.05671,rmse_val_loss: 0.06120\n",
      "Epoch [190/2000],rmse_train_loss: 0.05486,rmse_val_loss: 0.06451\n",
      "Epoch [200/2000],rmse_train_loss: 0.05632,rmse_val_loss: 0.07890\n",
      "Epoch [210/2000],rmse_train_loss: 0.05582,rmse_val_loss: 0.05695\n",
      "Epoch [220/2000],rmse_train_loss: 0.05209,rmse_val_loss: 0.06911\n",
      "Epoch [230/2000],rmse_train_loss: 0.05066,rmse_val_loss: 0.06483\n",
      "Epoch [240/2000],rmse_train_loss: 0.05178,rmse_val_loss: 0.06556\n",
      "Epoch [250/2000],rmse_train_loss: 0.05142,rmse_val_loss: 0.06048\n",
      "Epoch [260/2000],rmse_train_loss: 0.04606,rmse_val_loss: 0.05957\n",
      "Epoch [270/2000],rmse_train_loss: 0.04336,rmse_val_loss: 0.06404\n",
      "Epoch [280/2000],rmse_train_loss: 0.05573,rmse_val_loss: 0.07462\n",
      "Epoch [290/2000],rmse_train_loss: 0.04398,rmse_val_loss: 0.06354\n",
      "Epoch [300/2000],rmse_train_loss: 0.04537,rmse_val_loss: 0.05699\n",
      "Epoch [310/2000],rmse_train_loss: 0.03913,rmse_val_loss: 0.06285\n",
      "Epoch [320/2000],rmse_train_loss: 0.04731,rmse_val_loss: 0.05885\n",
      "Epoch [330/2000],rmse_train_loss: 0.04377,rmse_val_loss: 0.05960\n",
      "Epoch [340/2000],rmse_train_loss: 0.04063,rmse_val_loss: 0.05797\n",
      "Epoch [350/2000],rmse_train_loss: 0.03844,rmse_val_loss: 0.06778\n",
      "Epoch [360/2000],rmse_train_loss: 0.04595,rmse_val_loss: 0.06796\n",
      "Epoch [370/2000],rmse_train_loss: 0.06006,rmse_val_loss: 0.07272\n",
      "Epoch [380/2000],rmse_train_loss: 0.04832,rmse_val_loss: 0.05895\n",
      "Epoch [390/2000],rmse_train_loss: 0.06060,rmse_val_loss: 0.06774\n",
      "Epoch [400/2000],rmse_train_loss: 0.06174,rmse_val_loss: 0.06783\n",
      "Epoch [410/2000],rmse_train_loss: 0.05793,rmse_val_loss: 0.06582\n",
      "Epoch [420/2000],rmse_train_loss: 0.05157,rmse_val_loss: 0.07459\n",
      "Epoch [430/2000],rmse_train_loss: 0.03724,rmse_val_loss: 0.05679\n",
      "Epoch [440/2000],rmse_train_loss: 0.03998,rmse_val_loss: 0.05091\n",
      "Epoch [450/2000],rmse_train_loss: 0.03129,rmse_val_loss: 0.05309\n",
      "Epoch [460/2000],rmse_train_loss: 0.02657,rmse_val_loss: 0.04410\n",
      "Epoch [470/2000],rmse_train_loss: 0.03003,rmse_val_loss: 0.04663\n",
      "Epoch [480/2000],rmse_train_loss: 0.03063,rmse_val_loss: 0.06254\n",
      "Epoch [490/2000],rmse_train_loss: 0.02341,rmse_val_loss: 0.04422\n",
      "Epoch [500/2000],rmse_train_loss: 0.01972,rmse_val_loss: 0.04181\n",
      "Epoch [510/2000],rmse_train_loss: 0.02704,rmse_val_loss: 0.03982\n",
      "Epoch [520/2000],rmse_train_loss: 0.03136,rmse_val_loss: 0.05092\n",
      "Epoch [530/2000],rmse_train_loss: 0.03141,rmse_val_loss: 0.04112\n",
      "Epoch [540/2000],rmse_train_loss: 0.03690,rmse_val_loss: 0.06247\n",
      "Epoch [550/2000],rmse_train_loss: 0.03342,rmse_val_loss: 0.04689\n",
      "Epoch [560/2000],rmse_train_loss: 0.04337,rmse_val_loss: 0.04982\n",
      "Epoch [570/2000],rmse_train_loss: 0.03674,rmse_val_loss: 0.06207\n",
      "Epoch [580/2000],rmse_train_loss: 0.04098,rmse_val_loss: 0.05503\n",
      "Epoch [590/2000],rmse_train_loss: 0.03978,rmse_val_loss: 0.04441\n",
      "Epoch [600/2000],rmse_train_loss: 0.04178,rmse_val_loss: 0.05055\n",
      "Epoch [610/2000],rmse_train_loss: 0.03810,rmse_val_loss: 0.04491\n",
      "Epoch [620/2000],rmse_train_loss: 0.04326,rmse_val_loss: 0.05965\n",
      "Epoch [630/2000],rmse_train_loss: 0.06406,rmse_val_loss: 0.06761\n",
      "Epoch [640/2000],rmse_train_loss: 0.04009,rmse_val_loss: 0.04969\n",
      "Epoch [650/2000],rmse_train_loss: 0.03929,rmse_val_loss: 0.05113\n",
      "Epoch [660/2000],rmse_train_loss: 0.03669,rmse_val_loss: 0.05426\n",
      "Epoch [670/2000],rmse_train_loss: 0.04045,rmse_val_loss: 0.06198\n",
      "Epoch [680/2000],rmse_train_loss: 0.04850,rmse_val_loss: 0.05362\n",
      "Epoch [690/2000],rmse_train_loss: 0.03538,rmse_val_loss: 0.05770\n",
      "Epoch [700/2000],rmse_train_loss: 0.03284,rmse_val_loss: 0.05521\n",
      "Epoch [710/2000],rmse_train_loss: 0.03550,rmse_val_loss: 0.05918\n",
      "Epoch [720/2000],rmse_train_loss: 0.03078,rmse_val_loss: 0.06296\n",
      "Epoch [730/2000],rmse_train_loss: 0.02402,rmse_val_loss: 0.04607\n",
      "Epoch [740/2000],rmse_train_loss: 0.02594,rmse_val_loss: 0.04221\n",
      "Epoch [750/2000],rmse_train_loss: 0.03426,rmse_val_loss: 0.05761\n",
      "Epoch [760/2000],rmse_train_loss: 0.03082,rmse_val_loss: 0.05530\n",
      "Epoch [770/2000],rmse_train_loss: 0.02554,rmse_val_loss: 0.04780\n",
      "Epoch [780/2000],rmse_train_loss: 0.02123,rmse_val_loss: 0.03894\n",
      "Epoch [790/2000],rmse_train_loss: 0.02271,rmse_val_loss: 0.05014\n",
      "Epoch [800/2000],rmse_train_loss: 0.02179,rmse_val_loss: 0.04086\n",
      "Epoch [810/2000],rmse_train_loss: 0.02111,rmse_val_loss: 0.05286\n",
      "Epoch [820/2000],rmse_train_loss: 0.01764,rmse_val_loss: 0.05138\n",
      "Epoch [830/2000],rmse_train_loss: 0.02778,rmse_val_loss: 0.04593\n",
      "Epoch [840/2000],rmse_train_loss: 0.02548,rmse_val_loss: 0.04097\n",
      "Epoch [850/2000],rmse_train_loss: 0.01961,rmse_val_loss: 0.03705\n",
      "Epoch [860/2000],rmse_train_loss: 0.01954,rmse_val_loss: 0.03706\n",
      "Epoch [870/2000],rmse_train_loss: 0.04763,rmse_val_loss: 0.04128\n",
      "Epoch [880/2000],rmse_train_loss: 0.02887,rmse_val_loss: 0.03778\n",
      "Epoch [890/2000],rmse_train_loss: 0.02981,rmse_val_loss: 0.04979\n",
      "Epoch [900/2000],rmse_train_loss: 0.01898,rmse_val_loss: 0.03760\n",
      "Epoch [910/2000],rmse_train_loss: 0.02132,rmse_val_loss: 0.03864\n",
      "Epoch [920/2000],rmse_train_loss: 0.01569,rmse_val_loss: 0.04115\n",
      "Epoch [930/2000],rmse_train_loss: 0.01699,rmse_val_loss: 0.03983\n",
      "Epoch [940/2000],rmse_train_loss: 0.02464,rmse_val_loss: 0.04055\n",
      "Epoch [950/2000],rmse_train_loss: 0.01654,rmse_val_loss: 0.03683\n",
      "Epoch [960/2000],rmse_train_loss: 0.01866,rmse_val_loss: 0.04768\n",
      "Epoch [970/2000],rmse_train_loss: 0.01794,rmse_val_loss: 0.03890\n",
      "Epoch [980/2000],rmse_train_loss: 0.01586,rmse_val_loss: 0.04032\n",
      "Epoch [990/2000],rmse_train_loss: 0.01450,rmse_val_loss: 0.03715\n",
      "Epoch [1000/2000],rmse_train_loss: 0.01562,rmse_val_loss: 0.03902\n",
      "Epoch [1010/2000],rmse_train_loss: 0.01097,rmse_val_loss: 0.03804\n",
      "Epoch [1020/2000],rmse_train_loss: 0.01214,rmse_val_loss: 0.03405\n",
      "Epoch [1030/2000],rmse_train_loss: 0.02791,rmse_val_loss: 0.05078\n",
      "Epoch [1040/2000],rmse_train_loss: 0.03026,rmse_val_loss: 0.04219\n",
      "Epoch [1050/2000],rmse_train_loss: 0.02657,rmse_val_loss: 0.04521\n",
      "Epoch [1060/2000],rmse_train_loss: 0.02604,rmse_val_loss: 0.05180\n",
      "Epoch [1070/2000],rmse_train_loss: 0.02791,rmse_val_loss: 0.03909\n",
      "Epoch [1080/2000],rmse_train_loss: 0.01723,rmse_val_loss: 0.03971\n",
      "Epoch [1090/2000],rmse_train_loss: 0.01702,rmse_val_loss: 0.04632\n",
      "Epoch [1100/2000],rmse_train_loss: 0.03153,rmse_val_loss: 0.04383\n",
      "Epoch [1110/2000],rmse_train_loss: 0.01793,rmse_val_loss: 0.03851\n",
      "Epoch [1120/2000],rmse_train_loss: 0.01648,rmse_val_loss: 0.03927\n",
      "Epoch [1130/2000],rmse_train_loss: 0.01473,rmse_val_loss: 0.03965\n",
      "Epoch [1140/2000],rmse_train_loss: 0.01906,rmse_val_loss: 0.03597\n",
      "Epoch [1150/2000],rmse_train_loss: 0.01622,rmse_val_loss: 0.03819\n",
      "Epoch [1160/2000],rmse_train_loss: 0.01318,rmse_val_loss: 0.03732\n",
      "Epoch [1170/2000],rmse_train_loss: 0.00924,rmse_val_loss: 0.03469\n",
      "Epoch [1180/2000],rmse_train_loss: 0.01567,rmse_val_loss: 0.04173\n",
      "Epoch [1190/2000],rmse_train_loss: 0.03350,rmse_val_loss: 0.04377\n",
      "Epoch [1200/2000],rmse_train_loss: 0.02066,rmse_val_loss: 0.03893\n",
      "Epoch [1210/2000],rmse_train_loss: 0.01698,rmse_val_loss: 0.04240\n",
      "Epoch [1220/2000],rmse_train_loss: 0.01689,rmse_val_loss: 0.04581\n",
      "Epoch [1230/2000],rmse_train_loss: 0.04381,rmse_val_loss: 0.06411\n",
      "Epoch [1240/2000],rmse_train_loss: 0.02637,rmse_val_loss: 0.04084\n",
      "Epoch [1250/2000],rmse_train_loss: 0.02226,rmse_val_loss: 0.04871\n",
      "Epoch [1260/2000],rmse_train_loss: 0.02753,rmse_val_loss: 0.04636\n",
      "Epoch [1270/2000],rmse_train_loss: 0.02098,rmse_val_loss: 0.04431\n",
      "Epoch [1280/2000],rmse_train_loss: 0.01766,rmse_val_loss: 0.04202\n",
      "Epoch [1290/2000],rmse_train_loss: 0.02008,rmse_val_loss: 0.04551\n",
      "Epoch [1300/2000],rmse_train_loss: 0.01459,rmse_val_loss: 0.04372\n",
      "Epoch [1310/2000],rmse_train_loss: 0.02960,rmse_val_loss: 0.04654\n",
      "Epoch [1320/2000],rmse_train_loss: 0.01385,rmse_val_loss: 0.05256\n",
      "Epoch [1330/2000],rmse_train_loss: 0.01290,rmse_val_loss: 0.05315\n",
      "Epoch [1340/2000],rmse_train_loss: 0.01191,rmse_val_loss: 0.05357\n",
      "Epoch [1350/2000],rmse_train_loss: 0.01147,rmse_val_loss: 0.05221\n",
      "Epoch [1360/2000],rmse_train_loss: 0.00907,rmse_val_loss: 0.04867\n",
      "Epoch [1370/2000],rmse_train_loss: 0.03841,rmse_val_loss: 0.05143\n",
      "Epoch [1380/2000],rmse_train_loss: 0.02546,rmse_val_loss: 0.04898\n",
      "Epoch [1390/2000],rmse_train_loss: 0.02042,rmse_val_loss: 0.05107\n",
      "Epoch [1400/2000],rmse_train_loss: 0.01587,rmse_val_loss: 0.05030\n",
      "Epoch [1410/2000],rmse_train_loss: 0.01716,rmse_val_loss: 0.04971\n",
      "Epoch [1420/2000],rmse_train_loss: 0.01484,rmse_val_loss: 0.05071\n",
      "Epoch [1430/2000],rmse_train_loss: 0.01380,rmse_val_loss: 0.05057\n",
      "Epoch [1440/2000],rmse_train_loss: 0.01958,rmse_val_loss: 0.05364\n",
      "Epoch [1450/2000],rmse_train_loss: 0.01380,rmse_val_loss: 0.04597\n",
      "Epoch [1460/2000],rmse_train_loss: 0.01081,rmse_val_loss: 0.04702\n",
      "Epoch [1470/2000],rmse_train_loss: 0.01329,rmse_val_loss: 0.04540\n",
      "Epoch [1480/2000],rmse_train_loss: 0.01248,rmse_val_loss: 0.04850\n",
      "Epoch [1490/2000],rmse_train_loss: 0.01415,rmse_val_loss: 0.04950\n",
      "Epoch [1500/2000],rmse_train_loss: 0.01219,rmse_val_loss: 0.04571\n",
      "Epoch [1510/2000],rmse_train_loss: 0.01042,rmse_val_loss: 0.04152\n",
      "Epoch [1520/2000],rmse_train_loss: 0.01593,rmse_val_loss: 0.04585\n",
      "Epoch [1530/2000],rmse_train_loss: 0.00895,rmse_val_loss: 0.04651\n",
      "Epoch [1540/2000],rmse_train_loss: 0.00947,rmse_val_loss: 0.05242\n",
      "Epoch [1550/2000],rmse_train_loss: 0.02164,rmse_val_loss: 0.06098\n",
      "Epoch [1560/2000],rmse_train_loss: 0.01846,rmse_val_loss: 0.04643\n",
      "Epoch [1570/2000],rmse_train_loss: 0.01226,rmse_val_loss: 0.04629\n",
      "Epoch [1580/2000],rmse_train_loss: 0.01244,rmse_val_loss: 0.04687\n",
      "Epoch [1590/2000],rmse_train_loss: 0.01085,rmse_val_loss: 0.04563\n",
      "Epoch [1600/2000],rmse_train_loss: 0.00945,rmse_val_loss: 0.04871\n",
      "Epoch [1610/2000],rmse_train_loss: 0.01003,rmse_val_loss: 0.04554\n",
      "Epoch [1620/2000],rmse_train_loss: 0.00916,rmse_val_loss: 0.04444\n",
      "Epoch [1630/2000],rmse_train_loss: 0.01041,rmse_val_loss: 0.04386\n",
      "Epoch [1640/2000],rmse_train_loss: 0.00951,rmse_val_loss: 0.05266\n",
      "Epoch [1650/2000],rmse_train_loss: 0.01996,rmse_val_loss: 0.04530\n",
      "Epoch [1660/2000],rmse_train_loss: 0.01153,rmse_val_loss: 0.04629\n",
      "Epoch [1670/2000],rmse_train_loss: 0.01098,rmse_val_loss: 0.04330\n",
      "Epoch [1680/2000],rmse_train_loss: 0.00942,rmse_val_loss: 0.04331\n",
      "Epoch [1690/2000],rmse_train_loss: 0.01019,rmse_val_loss: 0.04427\n",
      "Epoch [1700/2000],rmse_train_loss: 0.00740,rmse_val_loss: 0.04491\n",
      "Epoch [1710/2000],rmse_train_loss: 0.00765,rmse_val_loss: 0.04424\n",
      "Epoch [1720/2000],rmse_train_loss: 0.00679,rmse_val_loss: 0.04729\n",
      "Epoch [1730/2000],rmse_train_loss: 0.00930,rmse_val_loss: 0.04432\n",
      "Epoch [1740/2000],rmse_train_loss: 0.01417,rmse_val_loss: 0.04487\n",
      "Epoch [1750/2000],rmse_train_loss: 0.03116,rmse_val_loss: 0.04135\n",
      "Epoch [1760/2000],rmse_train_loss: 0.04305,rmse_val_loss: 0.05485\n",
      "Epoch [1770/2000],rmse_train_loss: 0.03278,rmse_val_loss: 0.05826\n",
      "Epoch [1780/2000],rmse_train_loss: 0.02012,rmse_val_loss: 0.05403\n",
      "Epoch [1790/2000],rmse_train_loss: 0.01679,rmse_val_loss: 0.05253\n",
      "Epoch [1800/2000],rmse_train_loss: 0.01464,rmse_val_loss: 0.05045\n",
      "Epoch [1810/2000],rmse_train_loss: 0.01317,rmse_val_loss: 0.05203\n",
      "Epoch [1820/2000],rmse_train_loss: 0.01506,rmse_val_loss: 0.05135\n",
      "Epoch [1830/2000],rmse_train_loss: 0.05775,rmse_val_loss: 0.06079\n",
      "Epoch [1840/2000],rmse_train_loss: 0.02774,rmse_val_loss: 0.05382\n",
      "Epoch [1850/2000],rmse_train_loss: 0.01484,rmse_val_loss: 0.05237\n",
      "Epoch [1860/2000],rmse_train_loss: 0.01289,rmse_val_loss: 0.05288\n",
      "Epoch [1870/2000],rmse_train_loss: 0.01144,rmse_val_loss: 0.05562\n",
      "Epoch [1880/2000],rmse_train_loss: 0.01179,rmse_val_loss: 0.05242\n",
      "Epoch [1890/2000],rmse_train_loss: 0.01029,rmse_val_loss: 0.05539\n",
      "Epoch [1900/2000],rmse_train_loss: 0.01441,rmse_val_loss: 0.05450\n",
      "Epoch [1910/2000],rmse_train_loss: 0.01064,rmse_val_loss: 0.05933\n",
      "Epoch [1920/2000],rmse_train_loss: 0.01155,rmse_val_loss: 0.05193\n",
      "Epoch [1930/2000],rmse_train_loss: 0.00816,rmse_val_loss: 0.05352\n",
      "Epoch [1940/2000],rmse_train_loss: 0.00845,rmse_val_loss: 0.05376\n",
      "Epoch [1950/2000],rmse_train_loss: 0.00808,rmse_val_loss: 0.05258\n",
      "Epoch [1960/2000],rmse_train_loss: 0.01242,rmse_val_loss: 0.05310\n",
      "Epoch [1970/2000],rmse_train_loss: 0.01829,rmse_val_loss: 0.05387\n",
      "Epoch [1980/2000],rmse_train_loss: 0.01514,rmse_val_loss: 0.05599\n",
      "Epoch [1990/2000],rmse_train_loss: 0.00851,rmse_val_loss: 0.05199\n",
      "Epoch [2000/2000],rmse_train_loss: 0.01401,rmse_val_loss: 0.05028\n",
      "Epoch [10/2000],rmse_train_loss: 0.10855,rmse_val_loss: 0.09175\n",
      "Epoch [20/2000],rmse_train_loss: 0.09504,rmse_val_loss: 0.09245\n",
      "Epoch [30/2000],rmse_train_loss: 0.06929,rmse_val_loss: 0.06114\n",
      "Epoch [40/2000],rmse_train_loss: 0.07318,rmse_val_loss: 0.08159\n",
      "Epoch [50/2000],rmse_train_loss: 0.06866,rmse_val_loss: 0.06138\n",
      "Epoch [60/2000],rmse_train_loss: 0.06991,rmse_val_loss: 0.05968\n",
      "Epoch [70/2000],rmse_train_loss: 0.06609,rmse_val_loss: 0.06262\n",
      "Epoch [80/2000],rmse_train_loss: 0.06640,rmse_val_loss: 0.06239\n",
      "Epoch [90/2000],rmse_train_loss: 0.06703,rmse_val_loss: 0.05949\n",
      "Epoch [100/2000],rmse_train_loss: 0.06431,rmse_val_loss: 0.06819\n",
      "Epoch [110/2000],rmse_train_loss: 0.06914,rmse_val_loss: 0.05993\n",
      "Epoch [120/2000],rmse_train_loss: 0.06592,rmse_val_loss: 0.08428\n",
      "Epoch [130/2000],rmse_train_loss: 0.06245,rmse_val_loss: 0.05481\n",
      "Epoch [140/2000],rmse_train_loss: 0.06061,rmse_val_loss: 0.05081\n",
      "Epoch [150/2000],rmse_train_loss: 0.05970,rmse_val_loss: 0.05144\n",
      "Epoch [160/2000],rmse_train_loss: 0.06214,rmse_val_loss: 0.05069\n",
      "Epoch [170/2000],rmse_train_loss: 0.05763,rmse_val_loss: 0.06131\n",
      "Epoch [180/2000],rmse_train_loss: 0.04797,rmse_val_loss: 0.05395\n",
      "Epoch [190/2000],rmse_train_loss: 0.04992,rmse_val_loss: 0.04299\n",
      "Epoch [200/2000],rmse_train_loss: 0.04458,rmse_val_loss: 0.04951\n",
      "Epoch [210/2000],rmse_train_loss: 0.04547,rmse_val_loss: 0.04177\n",
      "Epoch [220/2000],rmse_train_loss: 0.04387,rmse_val_loss: 0.04646\n",
      "Epoch [230/2000],rmse_train_loss: 0.03838,rmse_val_loss: 0.04922\n",
      "Epoch [240/2000],rmse_train_loss: 0.04255,rmse_val_loss: 0.04399\n",
      "Epoch [250/2000],rmse_train_loss: 0.03863,rmse_val_loss: 0.04637\n",
      "Epoch [260/2000],rmse_train_loss: 0.03716,rmse_val_loss: 0.04032\n",
      "Epoch [270/2000],rmse_train_loss: 0.03425,rmse_val_loss: 0.05077\n",
      "Epoch [280/2000],rmse_train_loss: 0.03619,rmse_val_loss: 0.05279\n",
      "Epoch [290/2000],rmse_train_loss: 0.03206,rmse_val_loss: 0.05807\n",
      "Epoch [300/2000],rmse_train_loss: 0.02815,rmse_val_loss: 0.04997\n",
      "Epoch [310/2000],rmse_train_loss: 0.04266,rmse_val_loss: 0.04952\n",
      "Epoch [320/2000],rmse_train_loss: 0.03791,rmse_val_loss: 0.03588\n",
      "Epoch [330/2000],rmse_train_loss: 0.02765,rmse_val_loss: 0.05570\n",
      "Epoch [340/2000],rmse_train_loss: 0.02024,rmse_val_loss: 0.04672\n",
      "Epoch [350/2000],rmse_train_loss: 0.02235,rmse_val_loss: 0.06413\n",
      "Epoch [360/2000],rmse_train_loss: 0.02015,rmse_val_loss: 0.04743\n",
      "Epoch [370/2000],rmse_train_loss: 0.02272,rmse_val_loss: 0.04308\n",
      "Epoch [380/2000],rmse_train_loss: 0.02150,rmse_val_loss: 0.05645\n",
      "Epoch [390/2000],rmse_train_loss: 0.02424,rmse_val_loss: 0.05070\n",
      "Epoch [400/2000],rmse_train_loss: 0.01735,rmse_val_loss: 0.05616\n",
      "Epoch [410/2000],rmse_train_loss: 0.01972,rmse_val_loss: 0.04853\n",
      "Epoch [420/2000],rmse_train_loss: 0.01948,rmse_val_loss: 0.04517\n",
      "Epoch [430/2000],rmse_train_loss: 0.01692,rmse_val_loss: 0.04847\n",
      "Epoch [440/2000],rmse_train_loss: 0.02050,rmse_val_loss: 0.06250\n",
      "Epoch [450/2000],rmse_train_loss: 0.01966,rmse_val_loss: 0.04762\n",
      "Epoch [460/2000],rmse_train_loss: 0.01551,rmse_val_loss: 0.06488\n",
      "Epoch [470/2000],rmse_train_loss: 0.03809,rmse_val_loss: 0.04369\n",
      "Epoch [480/2000],rmse_train_loss: 0.02155,rmse_val_loss: 0.04582\n",
      "Epoch [490/2000],rmse_train_loss: 0.01710,rmse_val_loss: 0.06243\n",
      "Epoch [500/2000],rmse_train_loss: 0.01551,rmse_val_loss: 0.05462\n",
      "Epoch [510/2000],rmse_train_loss: 0.01433,rmse_val_loss: 0.03876\n",
      "Epoch [520/2000],rmse_train_loss: 0.01465,rmse_val_loss: 0.05051\n",
      "Epoch [530/2000],rmse_train_loss: 0.03705,rmse_val_loss: 0.05897\n",
      "Epoch [540/2000],rmse_train_loss: 0.03165,rmse_val_loss: 0.04388\n",
      "Epoch [550/2000],rmse_train_loss: 0.01872,rmse_val_loss: 0.05692\n",
      "Epoch [560/2000],rmse_train_loss: 0.01660,rmse_val_loss: 0.04834\n",
      "Epoch [570/2000],rmse_train_loss: 0.01338,rmse_val_loss: 0.05046\n",
      "Epoch [580/2000],rmse_train_loss: 0.01433,rmse_val_loss: 0.05251\n",
      "Epoch [590/2000],rmse_train_loss: 0.01267,rmse_val_loss: 0.06363\n",
      "Epoch [600/2000],rmse_train_loss: 0.01454,rmse_val_loss: 0.05713\n",
      "Epoch [610/2000],rmse_train_loss: 0.01347,rmse_val_loss: 0.04851\n",
      "Epoch [620/2000],rmse_train_loss: 0.04394,rmse_val_loss: 0.03638\n",
      "Epoch [630/2000],rmse_train_loss: 0.02930,rmse_val_loss: 0.05786\n",
      "Epoch [640/2000],rmse_train_loss: 0.01460,rmse_val_loss: 0.04684\n",
      "Epoch [650/2000],rmse_train_loss: 0.01362,rmse_val_loss: 0.04810\n",
      "Epoch [660/2000],rmse_train_loss: 0.01077,rmse_val_loss: 0.04442\n",
      "Epoch [670/2000],rmse_train_loss: 0.00944,rmse_val_loss: 0.04711\n",
      "Epoch [680/2000],rmse_train_loss: 0.01026,rmse_val_loss: 0.04738\n",
      "Epoch [690/2000],rmse_train_loss: 0.01353,rmse_val_loss: 0.05064\n",
      "Epoch [700/2000],rmse_train_loss: 0.01544,rmse_val_loss: 0.04243\n",
      "Epoch [710/2000],rmse_train_loss: 0.01783,rmse_val_loss: 0.05288\n",
      "Epoch [720/2000],rmse_train_loss: 0.01073,rmse_val_loss: 0.04668\n",
      "Epoch [730/2000],rmse_train_loss: 0.00789,rmse_val_loss: 0.04440\n",
      "Epoch [740/2000],rmse_train_loss: 0.03052,rmse_val_loss: 0.05084\n",
      "Epoch [750/2000],rmse_train_loss: 0.01588,rmse_val_loss: 0.04767\n",
      "Epoch [760/2000],rmse_train_loss: 0.01262,rmse_val_loss: 0.04403\n",
      "Epoch [770/2000],rmse_train_loss: 0.00894,rmse_val_loss: 0.04704\n",
      "Epoch [780/2000],rmse_train_loss: 0.01541,rmse_val_loss: 0.04787\n",
      "Epoch [790/2000],rmse_train_loss: 0.01515,rmse_val_loss: 0.04591\n",
      "Epoch [800/2000],rmse_train_loss: 0.00912,rmse_val_loss: 0.04292\n",
      "Epoch [810/2000],rmse_train_loss: 0.00716,rmse_val_loss: 0.04115\n",
      "Epoch [820/2000],rmse_train_loss: 0.00518,rmse_val_loss: 0.04038\n",
      "Epoch [830/2000],rmse_train_loss: 0.00896,rmse_val_loss: 0.04163\n",
      "Epoch [840/2000],rmse_train_loss: 0.00505,rmse_val_loss: 0.03993\n",
      "Epoch [850/2000],rmse_train_loss: 0.00697,rmse_val_loss: 0.04587\n",
      "Epoch [860/2000],rmse_train_loss: 0.00679,rmse_val_loss: 0.04274\n",
      "Epoch [870/2000],rmse_train_loss: 0.00619,rmse_val_loss: 0.04355\n",
      "Epoch [880/2000],rmse_train_loss: 0.00896,rmse_val_loss: 0.04536\n",
      "Epoch [890/2000],rmse_train_loss: 0.00944,rmse_val_loss: 0.04887\n",
      "Epoch [900/2000],rmse_train_loss: 0.01492,rmse_val_loss: 0.04345\n",
      "Epoch [910/2000],rmse_train_loss: 0.04438,rmse_val_loss: 0.04660\n",
      "Epoch [920/2000],rmse_train_loss: 0.02061,rmse_val_loss: 0.05636\n",
      "Epoch [930/2000],rmse_train_loss: 0.01134,rmse_val_loss: 0.05209\n",
      "Epoch [940/2000],rmse_train_loss: 0.00956,rmse_val_loss: 0.05020\n",
      "Epoch [950/2000],rmse_train_loss: 0.01151,rmse_val_loss: 0.05386\n",
      "Epoch [960/2000],rmse_train_loss: 0.00692,rmse_val_loss: 0.05500\n",
      "Epoch [970/2000],rmse_train_loss: 0.00748,rmse_val_loss: 0.05267\n",
      "Epoch [980/2000],rmse_train_loss: 0.00607,rmse_val_loss: 0.05244\n",
      "Epoch [990/2000],rmse_train_loss: 0.00936,rmse_val_loss: 0.04939\n",
      "Epoch [1000/2000],rmse_train_loss: 0.00552,rmse_val_loss: 0.05209\n",
      "Epoch [1010/2000],rmse_train_loss: 0.00669,rmse_val_loss: 0.04874\n",
      "Epoch [1020/2000],rmse_train_loss: 0.00367,rmse_val_loss: 0.04952\n",
      "Epoch [1030/2000],rmse_train_loss: 0.00596,rmse_val_loss: 0.05206\n",
      "Epoch [1040/2000],rmse_train_loss: 0.00445,rmse_val_loss: 0.04989\n",
      "Epoch [1050/2000],rmse_train_loss: 0.00385,rmse_val_loss: 0.05066\n",
      "Epoch [1060/2000],rmse_train_loss: 0.00763,rmse_val_loss: 0.04577\n",
      "Epoch [1070/2000],rmse_train_loss: 0.00815,rmse_val_loss: 0.04818\n",
      "Epoch [1080/2000],rmse_train_loss: 0.13049,rmse_val_loss: 0.09588\n",
      "Epoch [1090/2000],rmse_train_loss: 0.06745,rmse_val_loss: 0.05957\n",
      "Epoch [1100/2000],rmse_train_loss: 0.07015,rmse_val_loss: 0.07706\n",
      "Epoch [1110/2000],rmse_train_loss: 0.05936,rmse_val_loss: 0.04766\n",
      "Epoch [1120/2000],rmse_train_loss: 0.05856,rmse_val_loss: 0.04939\n",
      "Epoch [1130/2000],rmse_train_loss: 0.05700,rmse_val_loss: 0.05128\n",
      "Epoch [1140/2000],rmse_train_loss: 0.06038,rmse_val_loss: 0.05877\n",
      "Epoch [1150/2000],rmse_train_loss: 0.05416,rmse_val_loss: 0.04778\n",
      "Epoch [1160/2000],rmse_train_loss: 0.05844,rmse_val_loss: 0.04882\n",
      "Epoch [1170/2000],rmse_train_loss: 0.04940,rmse_val_loss: 0.04591\n",
      "Epoch [1180/2000],rmse_train_loss: 0.06958,rmse_val_loss: 0.07116\n",
      "Epoch [1190/2000],rmse_train_loss: 0.05966,rmse_val_loss: 0.04953\n",
      "Epoch [1200/2000],rmse_train_loss: 0.05228,rmse_val_loss: 0.04638\n",
      "Epoch [1210/2000],rmse_train_loss: 0.05065,rmse_val_loss: 0.04750\n",
      "Epoch [1220/2000],rmse_train_loss: 0.05444,rmse_val_loss: 0.05294\n",
      "Epoch [1230/2000],rmse_train_loss: 0.05644,rmse_val_loss: 0.04635\n",
      "Epoch [1240/2000],rmse_train_loss: 0.05517,rmse_val_loss: 0.05960\n",
      "Epoch [1250/2000],rmse_train_loss: 0.05099,rmse_val_loss: 0.05039\n",
      "Epoch [1260/2000],rmse_train_loss: 0.04908,rmse_val_loss: 0.04354\n",
      "Epoch [1270/2000],rmse_train_loss: 0.05094,rmse_val_loss: 0.04576\n",
      "Epoch [1280/2000],rmse_train_loss: 0.05056,rmse_val_loss: 0.04695\n",
      "Epoch [1290/2000],rmse_train_loss: 0.05444,rmse_val_loss: 0.03819\n",
      "Epoch [1300/2000],rmse_train_loss: 0.04413,rmse_val_loss: 0.04247\n",
      "Epoch [1310/2000],rmse_train_loss: 0.03562,rmse_val_loss: 0.03378\n",
      "Epoch [1320/2000],rmse_train_loss: 0.03224,rmse_val_loss: 0.04252\n",
      "Epoch [1330/2000],rmse_train_loss: 0.05370,rmse_val_loss: 0.03795\n",
      "Epoch [1340/2000],rmse_train_loss: 0.03647,rmse_val_loss: 0.03627\n",
      "Epoch [1350/2000],rmse_train_loss: 0.03680,rmse_val_loss: 0.04407\n",
      "Epoch [1360/2000],rmse_train_loss: 0.03182,rmse_val_loss: 0.03458\n",
      "Epoch [1370/2000],rmse_train_loss: 0.02835,rmse_val_loss: 0.03485\n",
      "Epoch [1380/2000],rmse_train_loss: 0.02635,rmse_val_loss: 0.03589\n",
      "Epoch [1390/2000],rmse_train_loss: 0.02384,rmse_val_loss: 0.03659\n",
      "Epoch [1400/2000],rmse_train_loss: 0.02775,rmse_val_loss: 0.05555\n",
      "Epoch [1410/2000],rmse_train_loss: 0.02724,rmse_val_loss: 0.04388\n",
      "Epoch [1420/2000],rmse_train_loss: 0.02446,rmse_val_loss: 0.04748\n",
      "Epoch [1430/2000],rmse_train_loss: 0.02516,rmse_val_loss: 0.04498\n",
      "Epoch [1440/2000],rmse_train_loss: 0.02123,rmse_val_loss: 0.03638\n",
      "Epoch [1450/2000],rmse_train_loss: 0.05051,rmse_val_loss: 0.04836\n",
      "Epoch [1460/2000],rmse_train_loss: 0.03486,rmse_val_loss: 0.04512\n",
      "Epoch [1470/2000],rmse_train_loss: 0.05477,rmse_val_loss: 0.05076\n",
      "Epoch [1480/2000],rmse_train_loss: 0.04187,rmse_val_loss: 0.05093\n",
      "Epoch [1490/2000],rmse_train_loss: 0.04777,rmse_val_loss: 0.04909\n",
      "Epoch [1500/2000],rmse_train_loss: 0.04655,rmse_val_loss: 0.04479\n",
      "Epoch [1510/2000],rmse_train_loss: 0.05028,rmse_val_loss: 0.05267\n",
      "Epoch [1520/2000],rmse_train_loss: 0.05929,rmse_val_loss: 0.04811\n",
      "Epoch [1530/2000],rmse_train_loss: 0.04611,rmse_val_loss: 0.05195\n",
      "Epoch [1540/2000],rmse_train_loss: 0.04041,rmse_val_loss: 0.05559\n",
      "Epoch [1550/2000],rmse_train_loss: 0.03338,rmse_val_loss: 0.05178\n",
      "Epoch [1560/2000],rmse_train_loss: 0.03017,rmse_val_loss: 0.05556\n",
      "Epoch [1570/2000],rmse_train_loss: 0.03766,rmse_val_loss: 0.04762\n",
      "Epoch [1580/2000],rmse_train_loss: 0.04362,rmse_val_loss: 0.04960\n",
      "Epoch [1590/2000],rmse_train_loss: 0.03943,rmse_val_loss: 0.05871\n",
      "Epoch [1600/2000],rmse_train_loss: 0.02763,rmse_val_loss: 0.05382\n",
      "Epoch [1610/2000],rmse_train_loss: 0.02420,rmse_val_loss: 0.05806\n",
      "Epoch [1620/2000],rmse_train_loss: 0.02685,rmse_val_loss: 0.06210\n",
      "Epoch [1630/2000],rmse_train_loss: 0.02936,rmse_val_loss: 0.05060\n",
      "Epoch [1640/2000],rmse_train_loss: 0.02241,rmse_val_loss: 0.05848\n",
      "Epoch [1650/2000],rmse_train_loss: 0.02314,rmse_val_loss: 0.04447\n",
      "Epoch [1660/2000],rmse_train_loss: 0.01835,rmse_val_loss: 0.05911\n",
      "Epoch [1670/2000],rmse_train_loss: 0.01657,rmse_val_loss: 0.05660\n",
      "Epoch [1680/2000],rmse_train_loss: 0.01623,rmse_val_loss: 0.04539\n",
      "Epoch [1690/2000],rmse_train_loss: 0.01603,rmse_val_loss: 0.05212\n",
      "Epoch [1700/2000],rmse_train_loss: 0.02102,rmse_val_loss: 0.05961\n",
      "Epoch [1710/2000],rmse_train_loss: 0.02009,rmse_val_loss: 0.04702\n",
      "Epoch [1720/2000],rmse_train_loss: 0.01490,rmse_val_loss: 0.06431\n",
      "Epoch [1730/2000],rmse_train_loss: 0.01077,rmse_val_loss: 0.06069\n",
      "Epoch [1740/2000],rmse_train_loss: 0.01634,rmse_val_loss: 0.05251\n",
      "Epoch [1750/2000],rmse_train_loss: 0.00836,rmse_val_loss: 0.05478\n",
      "Epoch [1760/2000],rmse_train_loss: 0.01721,rmse_val_loss: 0.05816\n",
      "Epoch [1770/2000],rmse_train_loss: 0.02383,rmse_val_loss: 0.04963\n",
      "Epoch [1780/2000],rmse_train_loss: 0.01781,rmse_val_loss: 0.05066\n",
      "Epoch [1790/2000],rmse_train_loss: 0.01652,rmse_val_loss: 0.05720\n",
      "Epoch [1800/2000],rmse_train_loss: 0.01163,rmse_val_loss: 0.05588\n",
      "Epoch [1810/2000],rmse_train_loss: 0.00931,rmse_val_loss: 0.05324\n",
      "Epoch [1820/2000],rmse_train_loss: 0.00725,rmse_val_loss: 0.05041\n",
      "Epoch [1830/2000],rmse_train_loss: 0.00488,rmse_val_loss: 0.05304\n",
      "Epoch [1840/2000],rmse_train_loss: 0.00518,rmse_val_loss: 0.05373\n",
      "Epoch [1850/2000],rmse_train_loss: 0.00526,rmse_val_loss: 0.05361\n",
      "Epoch [1860/2000],rmse_train_loss: 0.00639,rmse_val_loss: 0.05123\n",
      "Epoch [1870/2000],rmse_train_loss: 0.02119,rmse_val_loss: 0.04275\n",
      "Epoch [1880/2000],rmse_train_loss: 0.01239,rmse_val_loss: 0.05645\n",
      "Epoch [1890/2000],rmse_train_loss: 0.01349,rmse_val_loss: 0.05511\n",
      "Epoch [1900/2000],rmse_train_loss: 0.00970,rmse_val_loss: 0.05541\n",
      "Epoch [1910/2000],rmse_train_loss: 0.00806,rmse_val_loss: 0.04808\n",
      "Epoch [1920/2000],rmse_train_loss: 0.00632,rmse_val_loss: 0.05018\n",
      "Epoch [1930/2000],rmse_train_loss: 0.00819,rmse_val_loss: 0.05231\n",
      "Epoch [1940/2000],rmse_train_loss: 0.00845,rmse_val_loss: 0.05151\n",
      "Epoch [1950/2000],rmse_train_loss: 0.07408,rmse_val_loss: 0.06636\n",
      "Epoch [1960/2000],rmse_train_loss: 0.04400,rmse_val_loss: 0.04714\n",
      "Epoch [1970/2000],rmse_train_loss: 0.02380,rmse_val_loss: 0.04972\n",
      "Epoch [1980/2000],rmse_train_loss: 0.01867,rmse_val_loss: 0.05779\n",
      "Epoch [1990/2000],rmse_train_loss: 0.01808,rmse_val_loss: 0.05356\n",
      "Epoch [2000/2000],rmse_train_loss: 0.01804,rmse_val_loss: 0.05514\n"
     ]
    }
   ],
   "source": [
    "historys=[]\n",
    "lr=0.0001\n",
    "num_epochs=2000\n",
    "for fold in range(5):\n",
    "    model = vessel_ViT(depth=4)\n",
    "    net=model.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    history = np.zeros((0,3))\n",
    "\n",
    "    train_loader = train_loaders[fold]\n",
    "    val_loader = val_loaders[fold]\n",
    "\n",
    "    history = fit(net, optimizer, num_epochs, train_loader, val_loader, device, history,fold)\n",
    "    historys=np.append(historys,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys=historys.reshape(5,num_epochs,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(result_path+'/log', historys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
